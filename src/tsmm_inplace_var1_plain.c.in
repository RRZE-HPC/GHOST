/*!GHOST_AUTOGEN BLOCKDIM1 */
#include "ghost/config.h"
#include "ghost/types.h"
#include "ghost/math.h"
#include "ghost/instr.h"
#include "ghost/util.h"
#include "ghost/tsmm_inplace_var1_plain_gen.h"

#GHOST_SUBST BLOCKSZ ${BLOCKDIM1}

ghost_error ghost_tsmm_inplace__a_plain_d_BLOCKSZ_x(ghost_densemat *x, ghost_densemat *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH)
    ghost_error ret = GHOST_SUCCESS;

    ghost_lidx m = x->traits.ncols;
    ghost_lidx n = x->traits.nrows;
    ghost_lidx ncolsout = w->traits.ncols;

    double dalpha = *(double *)alpha;
    double dbeta = *(double *)beta;
    
    INFO_LOG("In in-place TSMM with arbitrary block size (%"PRLIDX"x%"PRLIDX") <- %f * (%"PRLIDX"x%"PRLIDX") * (%"PRLIDX"x%"PRLIDX")",n,ncolsout,dalpha,n,m,m,ncolsout);

    const double * const restrict wval = (const double *) w->val;
    double * const restrict xval = (double *) x->val;

    const ghost_lidx ldw = w->stride;
    const ghost_lidx ldx = x->stride;

    ghost_lidx i,j,s;

    /* construct dense wval... we can safely copy it as it is small! */
    double * restrict wtmp = NULL;
    ghost_lidx ncolsin_padded = PAD(BLOCKSZ,4);
    ghost_malloc_align((void**)&wtmp,ncolsin_padded*ncolsout*sizeof(double),32);
    memset(wtmp,0,ncolsin_padded*ncolsout*sizeof(double));
    for(s=0; s<ncolsout; s++)
    {
      for(j=0; j<BLOCKSZ; j++)
      {
        wtmp[s*ncolsin_padded+j] = dalpha*wval[s*ldw+j];
        if(s==j)
          wtmp[s*ncolsin_padded+j] += dbeta;
      }
    }

#pragma omp parallel for private(j,s) schedule(runtime)
    for (i=0; i<n; i++) {
        double tmp[ncolsout];
        for (s=0; s<ncolsout; s++) {
            tmp[s] = 0.;
#if BLOCKSZ > 1
#pragma vector aligned
#pragma vector always
#pragma ivdep
#pragma simd
#endif
#pragma unroll_and_jam(MIN(16,BLOCKSZ))
            for (j=0; j<BLOCKSZ; j++) {
                tmp[s] += xval[i*ldx+j]*wtmp[s*ncolsin_padded+j];
            }
        }
        memcpy(&xval[i*ldx],tmp,ncolsout*sizeof(double));
    }
    
    free(wtmp);
    
    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH)
    return ret;
}

ghost_error ghost_tsmm_inplace__a_plain_d_x_BLOCKSZ(ghost_densemat *x, ghost_densemat *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH)
    ghost_error ret = GHOST_SUCCESS;

    ghost_lidx m = x->traits.ncols;
    ghost_lidx n = x->traits.nrows;
    ghost_lidx ncolsin = w->traits.nrows;

    double dalpha = *(double *)alpha;
    double dbeta = *(double *)beta;
    
    INFO_LOG("In in-place TSMM with arbitrary block size (%"PRLIDX"x%"PRLIDX") <- %f * (%"PRLIDX"x%"PRLIDX") * (%"PRLIDX"x%"PRLIDX")",n,BLOCKSZ,dalpha,n,m,m,BLOCKSZ);

    const double * const restrict wval = (const double *) w->val;
    double * const restrict xval = (double *) x->val;

    const ghost_lidx ldw = w->stride;
    const ghost_lidx ldx = x->stride;

    ghost_lidx i,j,s;

    /* construct dense wval... we can safely copy it as it is small! */
    double * restrict wtmp = NULL;
    ghost_lidx ncolsin_padded = PAD(ncolsin,4);
    ghost_malloc_align((void**)&wtmp,ncolsin_padded*BLOCKSZ*sizeof(double),32);
    memset(wtmp,0,ncolsin_padded*BLOCKSZ*sizeof(double));
    for(s=0; s<BLOCKSZ; s++)
    {
      for(j=0; j<ncolsin; j++)
      {
        wtmp[s*ncolsin_padded+j] = dalpha*wval[s*ldw+j];
        if(s==j)
          wtmp[s*ncolsin_padded+j] += dbeta;
      }
    }

#pragma omp parallel for private(j,s) schedule(runtime)
    for (i=0; i<n; i++) {
        double tmp[BLOCKSZ];
#pragma unroll_and_jam(MIN(16,BLOCKSZ))
        for (s=0; s<BLOCKSZ; s++) {
            tmp[s] = 0.;
#pragma vector aligned
#pragma vector always
#pragma ivdep
#pragma simd
            for (j=0; j<ncolsin; j++) {
                tmp[s] += xval[i*ldx+j]*wtmp[s*ncolsin_padded+j];
            }
        }
        memcpy(&xval[i*ldx],tmp,BLOCKSZ*sizeof(double));
    }
    
    free(wtmp);
    
    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH)
    return ret;
}
