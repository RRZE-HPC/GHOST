#include "ghost/config.h"
#include "ghost/types.h"
#include "ghost/math.h"
#include "ghost/instr.h"
#include "ghost/util.h"
#include "ghost/omp.h"
#include "ghost/locality.h"
#include "ghost/tsmm_gen.h"
#include <math.h>
#include <float.h>
#include <omp.h>

#GHOST_FUNC_BEGIN#CFGK=${CFG_BLOCKVECTOR_SIZES}#CFGM=${CFG_BLOCKVECTOR_SIZES}
ghost_error_t ghost_tsmm__a_plain_d_CFGK_CFGM_1_rm_cm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    ghost_error_t ret = GHOST_SUCCESS;

    ghost_lidx_t k = w->traits.ncols;
    ghost_lidx_t m = v->traits.ncols;
    ghost_lidx_t n = v->traits.nrows;

    INFO_LOG("In TSMM with two fixed block sizes %"PRLIDX"x%"PRLIDX" <- %"PRLIDX"x%"PRLIDX" * %"PRLIDX"x%"PRLIDX,n,k,n,m,m,k);

    const double * const restrict vval = (const double *) v->val;
    const double * const restrict wval = (const double *) w->val;
    double * const restrict xval = (double *) x->val;

    const ghost_lidx_t ldv = v->stride;
    const ghost_lidx_t ldw = w->stride;
    const ghost_lidx_t ldx = x->stride;

    const double dalpha = *(double *)alpha;
    const double dbeta = *(double *)beta;
    ghost_lidx_t i,j,s;

    double tmp;
    
    if (fabs(dalpha-1.) > DBL_MIN || fabs(dbeta) > DBL_MIN) { // general case: X = b*X + a*V*W
#pragma omp parallel for private(j,s,tmp) schedule(runtime)
        for (i=0; i<n; i++) {
#if CFGK > 1
#pragma simd
#endif
            for (s=0; s<CFGK; s++) {
                tmp = dbeta*xval[i*ldx+s];
#if CFGK > 1
#pragma unroll_and_jam
#else
#if CFGM > 1
#pragma simd
#endif
#endif
                for (j=0; j<CFGM; j++) {
                    tmp += dalpha*vval[i*ldv+j]*wval[s*ldw+j];
                }
                xval[i*ldx+s] = tmp;
            }
        }
    } else { // common case: X = V*W
#pragma omp parallel for private(j,s,tmp) schedule(runtime)
        for (i=0; i<n; i++) {
#if CFGK > 1
#pragma simd
#endif
#pragma vector always aligned nontemporal
            for (s=0; s<CFGK; s++) {
                tmp = 0.;
#if CFGK > 1
#pragma unroll_and_jam
#else
#if CFGM > 1
#pragma simd
#endif
#endif
                for (j=0; j<CFGM; j++) {
                    tmp += vval[i*ldv+j]*wval[s*ldw+j];
                }
                xval[i*ldx+s] = tmp;
            }
        }
    }

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    return ret;
}
#GHOST_FUNC_END

#GHOST_FUNC_BEGIN#CFGK=${CFG_BLOCKVECTOR_SIZES}#CFGM=${CFG_BLOCKVECTOR_SIZES}
ghost_error_t ghost_tsmm__u_plain_d_CFGK_CFGM_1_rm_rm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    ghost_error_t ret = GHOST_SUCCESS;

    ghost_lidx_t k = w->traits.ncols;
    ghost_lidx_t m = v->traits.ncols;
    ghost_lidx_t n = v->traits.nrows;

    INFO_LOG("In TSMM with two fixed block sizes %"PRLIDX"x%"PRLIDX" <- %"PRLIDX"x%"PRLIDX" * %"PRLIDX"x%"PRLIDX,n,k,n,m,m,k);

    const double * const restrict vval = (const double *) v->val;
    const double * const restrict wval = (const double *) w->val;
    double * const restrict xval = (double *) x->val;

    const ghost_lidx_t ldv = v->stride;
    const ghost_lidx_t ldw = w->stride;
    const ghost_lidx_t ldx = x->stride;

    const double dalpha = *(double *)alpha;
    const double dbeta = *(double *)beta;
    ghost_lidx_t i,j,s;

    double tmp;
    
#pragma omp parallel for private(j,s,tmp) schedule(runtime)
    for (i=0; i<n; i++) {
#if CFGK > 1
#pragma simd
#endif
        for (s=0; s<CFGK; s++) {
            tmp = dbeta*xval[i*ldx+s];
#if CFGK > 1
#pragma unroll_and_jam
#else
#if CFGM > 1
#pragma simd
#endif
#endif
            for (j=0; j<CFGM; j++) {
                tmp += dalpha*vval[i*ldv+j]*wval[j*ldw+s];
            }
            xval[i*ldx+s] = tmp;
        }
    }

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    return ret;
}
#GHOST_FUNC_END

#GHOST_FUNC_BEGIN#CFGK=${CFG_BLOCKVECTOR_SIZES}#CFGM=${CFG_BLOCKVECTOR_SIZES}#OUTERUNROLL=8
ghost_error_t ghost_tsmm__a_plain_d_CFGK_CFGM_OUTERUNROLL_cm_cm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    ghost_error_t ret = GHOST_SUCCESS;

    ghost_lidx_t k = w->traits.ncols;
    ghost_lidx_t m = v->traits.ncols;
    ghost_lidx_t n = v->traits.nrows;
    
    if (n%OUTERUNROLL) {
        n+=(OUTERUNROLL-n%OUTERUNROLL);
        INFO_LOG("Padding large dimension to %d\n",n);
    }

    INFO_LOG("In TSMM with two fixed block sizes %"PRLIDX"x%"PRLIDX" <- %"PRLIDX"x%"PRLIDX" * %"PRLIDX"x%"PRLIDX,n,k,n,m,m,k);

    const double * const restrict vval = (const double *) v->val;
    const double * const restrict wval = (const double *) w->val;
    double * const restrict xval = (double *) x->val;

    const ghost_lidx_t ldv = v->stride;
    const ghost_lidx_t ldw = w->stride;
    const ghost_lidx_t ldx = x->stride;

    const double dalpha = *(double *)alpha;
    const double dbeta = *(double *)beta;
    ghost_lidx_t i,j,s,t;
    
    double *wscale;
    ghost_malloc_align((void **)&wscale,CFGM*CFGK*sizeof(double),64);
        
    for (s=0; s<CFGK; s++) {
        for (j=0; j<CFGM; j++) {
            wscale[s*CFGM+j] = dalpha*wval[s*ldw+j];
        }
    }
    
  
    if (fabs(dbeta) > DBL_MIN) { 
#pragma omp parallel 
        {
            double *tmp;
            ghost_malloc_align((void **)&tmp,OUTERUNROLL*sizeof(double),64);
            
#pragma omp for private(j,s,t) schedule(runtime)
            for (i=0; i<=n-OUTERUNROLL; i+=OUTERUNROLL) {

#pragma unroll_and_jam(MIN(16,CFGK))
                for (s=0; s<CFGK; s++) {

#pragma vector aligned
#pragma simd
                    for (t=0; t<OUTERUNROLL; t++) {
                        tmp[t] = dbeta*xval[s*ldx+i+t];
                    }

#pragma unroll_and_jam(MIN(16,CFGM))
                    for (j=0; j<CFGM; j++) {
                        double wtmp = wscale[s*CFGM+j];

#pragma vector always
#pragma ivdep
#pragma vector aligned
#pragma simd
                        for (t=0; t<OUTERUNROLL; t++) {
                            tmp[t] += vval[j*ldv+i+t]*wtmp;
                        }
                    }

#pragma vector aligned
#pragma simd
                    for (t=0; t<OUTERUNROLL; t++) {
                        xval[s*ldx+i+t] = tmp[t];
                    }
                }
            }
            free(tmp);
        }
    } else {
#pragma omp parallel 
        {
            double *tmp;
            ghost_malloc_align((void **)&tmp,OUTERUNROLL*sizeof(double),64);
            
#pragma omp for private(j,s,t) schedule(runtime)
            for (i=0; i<=n-OUTERUNROLL; i+=OUTERUNROLL) {

#pragma unroll_and_jam(MIN(16,CFGK))
                for (s=0; s<CFGK; s++) {

#pragma vector aligned
#pragma simd
                    for (t=0; t<OUTERUNROLL; t++) {
                        tmp[t] = 0.;
                    }

#pragma unroll_and_jam(MIN(16,CFGM))
                    for (j=0; j<CFGM; j++) {
                        double wtmp = wscale[s*CFGM+j];

#pragma vector always
#pragma ivdep
#pragma vector aligned
#pragma simd
                        for (t=0; t<OUTERUNROLL; t++) {
                            tmp[t] += vval[j*ldv+i+t]*wtmp;
                        }
                    }

#pragma vector nontemporal
#pragma vector aligned
#pragma simd
                    for (t=0; t<OUTERUNROLL; t++) {
                        xval[s*ldx+i+t] = tmp[t];
                    }
                }
            }
            free(tmp);
        }
    }


    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    return ret;
}
#GHOST_FUNC_END

#GHOST_FUNC_BEGIN#CFGK=${CFG_BLOCKVECTOR_SIZES}#CFGM=${CFG_BLOCKVECTOR_SIZES}#OUTERUNROLL=8
ghost_error_t ghost_tsmm__u_plain_d_CFGK_CFGM_OUTERUNROLL_cm_cm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    ghost_error_t ret = GHOST_SUCCESS;

    ghost_lidx_t k = w->traits.ncols;
    ghost_lidx_t m = v->traits.ncols;
    ghost_lidx_t n = v->traits.nrows;
    
    if (n%OUTERUNROLL) {
        n+=(OUTERUNROLL-n%OUTERUNROLL);
        INFO_LOG("Padding large dimension to %d\n",n);
    }

    INFO_LOG("In TSMM with two fixed block sizes %"PRLIDX"x%"PRLIDX" <- %"PRLIDX"x%"PRLIDX" * %"PRLIDX"x%"PRLIDX,n,k,n,m,m,k);

    const double * const restrict vval = (const double *) v->val;
    const double * const restrict wval = (const double *) w->val;
    double * const restrict xval = (double *) x->val;

    const ghost_lidx_t ldv = v->stride;
    const ghost_lidx_t ldw = w->stride;
    const ghost_lidx_t ldx = x->stride;

    const double dalpha = *(double *)alpha;
    const double dbeta = *(double *)beta;
    ghost_lidx_t i,j,s,t;
    
    double *wscale;
    ghost_malloc((void **)&wscale,CFGM*CFGK*sizeof(double));
        
    for (s=0; s<CFGK; s++) {
        for (j=0; j<CFGM; j++) {
            wscale[s*CFGM+j] = dalpha*wval[s*ldw+j];
        }
    }
    
#pragma omp parallel 
    {
    double *tmp;
    ghost_malloc_align((void **)&tmp,OUTERUNROLL*sizeof(double),64);
    
#pragma omp for private(j,s,t) schedule(runtime)
    for (i=0; i<=n-OUTERUNROLL; i+=OUTERUNROLL) {

#pragma unroll_and_jam(MIN(16,CFGK))
        for (s=0; s<CFGK; s++) {

#pragma vector unaligned
#pragma simd
            for (t=0; t<OUTERUNROLL; t++) {
                tmp[t] = dbeta*xval[s*ldx+i+t];
            }

#pragma unroll_and_jam(MIN(16,CFGM))
            for (j=0; j<CFGM; j++) {

#pragma vector always
#pragma ivdep
#pragma vector unaligned
#pragma simd
                for (t=0; t<OUTERUNROLL; t++) {
                    tmp[t] += vval[j*ldv+i+t]*wscale[s*CFGM+j];
                }
            }

#pragma vector always
#pragma ivdep
#pragma vector unaligned
#pragma simd
            for (t=0; t<OUTERUNROLL; t++) {
                xval[s*ldx+i+t] = tmp[t];
            }
        }
    }
    free(tmp);
    }
    free(wscale);

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    return ret;
}
#GHOST_FUNC_END

ghost_error_t ghost_tsmm__u_plain_d_x_x_1_rm_cm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    ghost_error_t ret = GHOST_SUCCESS;

    ghost_lidx_t k = w->traits.ncols;
    ghost_lidx_t m = v->traits.ncols;
    ghost_lidx_t n = v->traits.nrows;

    
    INFO_LOG("In TSMM with arbitrary block sizes %"PRLIDX"x%"PRLIDX" <- %"PRLIDX"x%"PRLIDX" * %"PRLIDX"x%"PRLIDX,n,k,n,m,m,k);

    const double * const restrict vval = (const double *) v->val;
    const double * const restrict wval = (const double *) w->val;
    double * const restrict xval = (double *) x->val;

    const ghost_lidx_t ldv = v->stride;
    const ghost_lidx_t ldw = w->stride;
    const ghost_lidx_t ldx = x->stride;

    const double dalpha = *(double *)alpha;
    const double dbeta = *(double *)beta;
    ghost_lidx_t i,j,s;
    
    if (w->traits.ncolspadded <= 4) 
    {
#pragma omp parallel for private(j,s) schedule(runtime)
        for (i=0; i<n; i++) {
            for (s=0; s<w->traits.ncols; s++) {
                xval[i*ldx+s] = dbeta*xval[i*ldx+s];
#pragma simd
#pragma vector aligned
#pragma vector always
#pragma ivdep
                for (j=0; j<m; j++) {
                    xval[i*ldx+s] += dalpha*vval[i*ldv+j]*wval[s*ldw+j];
                }
            }
        }
    } 
    else 
    {
#pragma omp parallel for private(j,s) schedule(runtime)
        for (i=0; i<n; i++) {
#pragma simd
#pragma vector aligned
#pragma vector always
#pragma ivdep
            for (s=0; s<w->traits.ncols; s++) {
                xval[i*ldx+s] = dbeta*xval[i*ldx+s];
            }
            for (j=0; j<m; j++) {
#pragma simd
#pragma vector aligned
#pragma vector always
#pragma ivdep
                for (s=0; s<w->traits.ncols; s++) {
                    xval[i*ldx+s] += dalpha*vval[i*ldv+j]*wval[s*ldw+j];
                }
            }
        }
    }    

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    return ret;
}

ghost_error_t ghost_tsmm__u_plain_d_x_x_1_cm_cm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    ghost_error_t ret = GHOST_SUCCESS;

    ghost_lidx_t k = w->traits.ncols;
    ghost_lidx_t m = v->traits.ncols;
    ghost_lidx_t n = v->traits.nrows;

    
    INFO_LOG("In TSMM with arbitrary block sizes %"PRLIDX"x%"PRLIDX" <- %"PRLIDX"x%"PRLIDX" * %"PRLIDX"x%"PRLIDX,n,k,n,m,m,k);

    const double * const restrict vval = (const double *) v->val;
    const double * const restrict wval = (const double *) w->val;
    double * const restrict xval = (double *) x->val;

    const ghost_lidx_t ldv = v->stride;
    const ghost_lidx_t ldw = w->stride;
    const ghost_lidx_t ldx = x->stride;

    const double dalpha = *(double *)alpha;
    const double dbeta = *(double *)beta;
    ghost_lidx_t i,j,s;
    
    if (w->traits.ncolspadded <= 4) 
    {
#pragma omp parallel for private(j,s) schedule(runtime)
        for (i=0; i<n; i++) {
            for (s=0; s<w->traits.ncols; s++) {
                xval[s*ldx+i] = dbeta*xval[s*ldx+i];
#pragma simd
#pragma vector unaligned
#pragma vector always
#pragma ivdep
                for (j=0; j<m; j++) {
                    xval[s*ldx+i] += dalpha*vval[j*ldv+i]*wval[s*ldw+j];
                }
            }
        }
    } 
    else 
    {
#pragma omp parallel for private(j,s) schedule(runtime)
        for (i=0; i<n; i++) {
#pragma simd
#pragma vector unaligned
#pragma vector always
#pragma ivdep
            for (s=0; s<w->traits.ncols; s++) {
                xval[s*ldx+i] = dbeta*xval[s*ldx+i];
            }
            for (j=0; j<m; j++) {
#pragma simd
#pragma vector unaligned
#pragma vector always
#pragma ivdep
                for (s=0; s<w->traits.ncols; s++) {
                    xval[s*ldx+i] += dalpha*vval[j*ldv+i]*wval[s*ldw+j];
                }
            }
        }
    }    

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    return ret;
}

ghost_error_t ghost_tsmm__u_plain_d_x_x_1_rm_rm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    ghost_error_t ret = GHOST_SUCCESS;

    ghost_lidx_t k = w->traits.ncols;
    ghost_lidx_t m = v->traits.ncols;
    ghost_lidx_t n = v->traits.nrows;

    
    INFO_LOG("In TSMM with arbitrary block sizes %"PRLIDX"x%"PRLIDX" <- %"PRLIDX"x%"PRLIDX" * %"PRLIDX"x%"PRLIDX,n,k,n,m,m,k);

    const double * const restrict vval = (const double *) v->val;
    const double * const restrict wval = (const double *) w->val;
    double * const restrict xval = (double *) x->val;

    const ghost_lidx_t ldv = v->stride;
    const ghost_lidx_t ldw = w->stride;
    const ghost_lidx_t ldx = x->stride;

    const double dalpha = *(double *)alpha;
    const double dbeta = *(double *)beta;
    ghost_lidx_t i,j,s;
    
    if (w->traits.ncolspadded <= 4) 
    {
#pragma omp parallel for private(j,s) schedule(runtime)
        for (i=0; i<n; i++) {
            for (s=0; s<w->traits.ncols; s++) {
                xval[i*ldx+s] = dbeta*xval[i*ldx+s];
#pragma simd
#pragma vector aligned
#pragma vector always
#pragma ivdep
                for (j=0; j<m; j++) {
                    xval[i*ldx+s] += dalpha*vval[i*ldv+j]*wval[j*ldw+s];
                }
            }
        }
    } 
    else 
    {
#pragma omp parallel for private(j,s) schedule(runtime)
        for (i=0; i<n; i++) {
#pragma simd
#pragma vector aligned
#pragma vector always
#pragma ivdep
            for (s=0; s<w->traits.ncols; s++) {
                xval[i*ldx+s] = dbeta*xval[i*ldx+s];
            }
            for (j=0; j<m; j++) {
#pragma simd
#pragma vector aligned
#pragma vector always
#pragma ivdep
                for (s=0; s<w->traits.ncols; s++) {
                    xval[i*ldx+s] += dalpha*vval[i*ldv+j]*wval[j*ldw+s];
                }
            }
        }
    }    

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    return ret;
}

ghost_error_t ghost_tsmm__u_plain_z_x_x_1_cm_cm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    ghost_error_t ret = GHOST_SUCCESS;

    ghost_lidx_t k = w->traits.ncols;
    ghost_lidx_t m = v->traits.ncols;
    ghost_lidx_t n = v->traits.nrows;

    
    INFO_LOG("In TSMM with arbitrary block sizes %"PRLIDX"x%"PRLIDX" <- %"PRLIDX"x%"PRLIDX" * %"PRLIDX"x%"PRLIDX,n,k,n,m,m,k);

    const double complex * const restrict vval = (const double complex*) v->val;
    const double complex * const restrict wval = (const double complex*) w->val;
    double complex * const restrict xval = (double complex*) x->val;

    const ghost_lidx_t ldv = v->stride;
    const ghost_lidx_t ldw = w->stride;
    const ghost_lidx_t ldx = x->stride;

    const double complex dalpha = *(double complex *)alpha;
    const double complex dbeta = *(double complex *)beta;
    ghost_lidx_t i,j,s;
    
    if (w->traits.ncolspadded <= 4) 
    {
#pragma omp parallel for private(j,s) schedule(runtime)
        for (i=0; i<n; i++) {
            for (s=0; s<w->traits.ncols; s++) {
                xval[s*ldx+i] = dbeta*xval[s*ldx+i];
#pragma simd
#pragma vector always
#pragma ivdep
                for (j=0; j<m; j++) {
                    xval[s*ldx+i] += dalpha*vval[j*ldv+i]*wval[s*ldw+j];
                }
            }
        }
    } 
    else 
    {
#pragma omp parallel for private(j,s) schedule(runtime)
        for (i=0; i<n; i++) {
#pragma simd
#pragma vector always
#pragma ivdep
            for (s=0; s<w->traits.ncols; s++) {
                xval[s*ldx+i] = dbeta*xval[s*ldx+i];
            }
            for (j=0; j<m; j++) {
#pragma simd
#pragma vector always
#pragma ivdep
                for (s=0; s<w->traits.ncols; s++) {
                    xval[s*ldx+i] += dalpha*vval[j*ldv+i]*wval[s*ldw+j];
                }
            }
        }
    }    

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    return ret;
}

#GHOST_FUNC_BEGIN#CFGK=${CFG_BLOCKVECTOR_SIZES}
ghost_error_t ghost_tsmm__u_plain_d_CFGK_x_1_rm_cm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    ghost_error_t ret = GHOST_SUCCESS;

    ghost_lidx_t m = v->traits.ncols;
    ghost_lidx_t n = v->traits.nrows;

    
    INFO_LOG("In TSMM with fixed K %"PRLIDX" and arbitrary M %"PRLIDX": %"PRLIDX"x%"PRLIDX" <- %"PRLIDX"x%"PRLIDX" * %"PRLIDX"x%"PRLIDX,CFGK,m,n,CFGK,n,m,m,CFGK);

    const double * const restrict vval = (const double *) v->val;
    const double * const restrict wval = (const double *) w->val;
    double * const restrict xval = (double *) x->val;

    const ghost_lidx_t ldv = v->stride;
    const ghost_lidx_t ldw = w->stride;
    const ghost_lidx_t ldx = x->stride;

    const double dalpha = *(double *)alpha;
    const double dbeta = *(double *)beta;
    ghost_lidx_t i,j,s;
    
#pragma omp parallel for private(j,s) schedule(runtime)
    for (i=0; i<n; i++) {
        for (s=0; s<CFGK; s++) {
            xval[i*ldx+s] = dbeta*xval[i*ldx+s];
#pragma simd
            for (j=0; j<m; j++) {
                xval[i*ldx+s] += dalpha*vval[i*ldv+j]*wval[s*ldw+j];
            }
        }
    }

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    return ret;
}
#GHOST_FUNC_END

#GHOST_FUNC_BEGIN#CFGM=${CFG_BLOCKVECTOR_SIZES}
ghost_error_t ghost_tsmm__u_plain_d_x_CFGM_1_rm_cm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    ghost_error_t ret = GHOST_SUCCESS;

    ghost_lidx_t k = x->traits.ncols;
    ghost_lidx_t n = v->traits.nrows;

    
    INFO_LOG("In TSMM with fixed M %"PRLIDX" and arbitrary K %"PRLIDX": %"PRLIDX"x%"PRLIDX" <- %"PRLIDX"x%"PRLIDX" * %"PRLIDX"x%"PRLIDX,CFGM,k,n,CFGM,n,k,k,CFGM);

    const double * const restrict vval = (const double *) v->val;
    const double * const restrict wval = (const double *) w->val;
    double * const restrict xval = (double *) x->val;

    const ghost_lidx_t ldv = v->stride;
    const ghost_lidx_t ldw = w->stride;
    const ghost_lidx_t ldx = x->stride;

    const double dalpha = *(double *)alpha;
    const double dbeta = *(double *)beta;
    ghost_lidx_t i,j,s;
    
#pragma omp parallel for private(j,s) schedule(runtime)
    for (i=0; i<n; i++) {
        for (s=0; s<k; s++) {
            xval[i*ldx+s] = dbeta*xval[i*ldx+s];
#pragma simd
            for (j=0; j<CFGM; j++) {
                xval[i*ldx+s] += dalpha*vval[i*ldv+j]*wval[s*ldw+j];
            }
        }
    }

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    return ret;
}
#GHOST_FUNC_END

ghost_error_t ghost_tsmm__u_plain_z_x_x_1_rm_cm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    ghost_error_t ret = GHOST_SUCCESS;

    ghost_lidx_t k = w->traits.ncols;
    ghost_lidx_t m = v->traits.ncols;
    ghost_lidx_t n = v->traits.nrows;

    
    INFO_LOG("In TSMM with arbitrary block sizes %"PRLIDX"x%"PRLIDX" <- %"PRLIDX"x%"PRLIDX" * %"PRLIDX"x%"PRLIDX,n,k,n,m,m,k);

    const double complex * const restrict vval = (const double complex*) v->val;
    const double complex * const restrict wval = (const double complex*) w->val;
    double complex * const restrict xval = (double complex*) x->val;

    const ghost_lidx_t ldv = v->stride;
    const ghost_lidx_t ldw = w->stride;
    const ghost_lidx_t ldx = x->stride;

    const double complex dalpha = *(double complex *)alpha;
    const double complex dbeta = *(double complex *)beta;
    ghost_lidx_t i,j,s;
    
    if (w->traits.ncolspadded <= 4) 
    {
#pragma omp parallel for private(j,s) schedule(runtime)
        for (i=0; i<n; i++) {
            for (s=0; s<w->traits.ncols; s++) {
                xval[i*ldx+s] = dbeta*xval[i*ldx+s];
#pragma simd
#pragma vector aligned
#pragma vector always
#pragma ivdep
                for (j=0; j<m; j++) {
                    xval[i*ldx+s] += dalpha*vval[i*ldv+j]*wval[s*ldw+j];
                }
            }
        }
    } 
    else 
    {
#pragma omp parallel for private(j,s) schedule(runtime)
        for (i=0; i<n; i++) {
#pragma simd
#pragma vector aligned
#pragma vector always
#pragma ivdep
            for (s=0; s<w->traits.ncols; s++) {
                xval[i*ldx+s] = dbeta*xval[i*ldx+s];
            }
            for (j=0; j<m; j++) {
#pragma simd
#pragma vector aligned
#pragma vector always
#pragma ivdep
                for (s=0; s<w->traits.ncols; s++) {
                    xval[i*ldx+s] += dalpha*vval[i*ldv+j]*wval[s*ldw+j];
                }
            }
        }
    }    

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    return ret;
}

ghost_error_t ghost_tsmm__u_plain_z_x_x_1_rm_rm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    ghost_error_t ret = GHOST_SUCCESS;

    ghost_lidx_t k = w->traits.ncols;
    ghost_lidx_t m = v->traits.ncols;
    ghost_lidx_t n = v->traits.nrows;

    
    INFO_LOG("In TSMM with arbitrary block sizes %"PRLIDX"x%"PRLIDX" <- %"PRLIDX"x%"PRLIDX" * %"PRLIDX"x%"PRLIDX,n,k,n,m,m,k);

    const double complex * const restrict vval = (const double complex*) v->val;
    const double complex * const restrict wval = (const double complex*) w->val;
    double complex * const restrict xval = (double complex*) x->val;

    const ghost_lidx_t ldv = v->stride;
    const ghost_lidx_t ldw = w->stride;
    const ghost_lidx_t ldx = x->stride;

    const double complex dalpha = *(double complex *)alpha;
    const double complex dbeta = *(double complex *)beta;
    ghost_lidx_t i,j,s;
    
    if (w->traits.ncolspadded <= 4) 
    {
#pragma omp parallel for private(j,s) schedule(runtime)
        for (i=0; i<n; i++) {
            for (s=0; s<w->traits.ncols; s++) {
                xval[i*ldx+s] = dbeta*xval[i*ldx+s];
#pragma simd
#pragma vector aligned
#pragma vector always
#pragma ivdep
                for (j=0; j<m; j++) {
                    xval[i*ldx+s] += dalpha*vval[i*ldv+j]*wval[j*ldw+s];
                }
            }
        }
    } 
    else 
    {
#pragma omp parallel for private(j,s) schedule(runtime)
        for (i=0; i<n; i++) {
#pragma simd
#pragma vector aligned
#pragma vector always
#pragma ivdep
            for (s=0; s<w->traits.ncols; s++) {
                xval[i*ldx+s] = dbeta*xval[i*ldx+s];
            }
            for (j=0; j<m; j++) {
#pragma simd
#pragma vector aligned
#pragma vector always
#pragma ivdep
                for (s=0; s<w->traits.ncols; s++) {
                    xval[i*ldx+s] += dalpha*vval[i*ldv+j]*wval[j*ldw+s];
                }
            }
        }
    }    

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    return ret;
}

#GHOST_FUNC_BEGIN#CFGK=${CFG_BLOCKVECTOR_SIZES}#CFGM=${CFG_BLOCKVECTOR_SIZES}
ghost_error_t ghost_tsmm__u_plain_z_CFGK_CFGM_1_rm_cm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    ghost_error_t ret = GHOST_SUCCESS;

    ghost_lidx_t k = w->traits.ncols;
    ghost_lidx_t m = v->traits.ncols;
    ghost_lidx_t n = v->traits.nrows;

    INFO_LOG("In TSMM with two fixed block sizes %"PRLIDX"x%"PRLIDX" <- %"PRLIDX"x%"PRLIDX" * %"PRLIDX"x%"PRLIDX,n,k,n,m,m,k);

    const double complex * const restrict vval = (const double complex*) v->val;
    const double complex * const restrict wval = (const double complex*) w->val;
    double complex * const restrict xval = (double complex*) x->val;

    const ghost_lidx_t ldv = v->stride;
    const ghost_lidx_t ldw = w->stride;
    const ghost_lidx_t ldx = x->stride;

    const double complex dalpha = *(double complex *)alpha;
    const double complex dbeta = *(double complex *)beta;
    ghost_lidx_t i,j,s;

    double complex tmp;
    
#pragma omp parallel for private(j,s,tmp) schedule(runtime)
    for (i=0; i<n; i++) {
#if CFGK > 1
#pragma simd
#endif
        for (s=0; s<CFGK; s++) {
            tmp = dbeta*xval[i*ldx+s];
#if CFGK > 1
#pragma unroll_and_jam
#else
#if CFGM > 1
#pragma simd
#endif
#endif
            for (j=0; j<CFGM; j++) {
                tmp += dalpha*vval[i*ldv+j]*wval[s*ldw+j];
            }
            xval[i*ldx+s] = tmp;
        }
    }

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    return ret;
}
#GHOST_FUNC_END

#GHOST_FUNC_BEGIN#CFGK=${CFG_BLOCKVECTOR_SIZES}#CFGM=${CFG_BLOCKVECTOR_SIZES}
ghost_error_t ghost_tsmm__u_plain_z_CFGK_CFGM_1_rm_rm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    ghost_error_t ret = GHOST_SUCCESS;

    ghost_lidx_t k = w->traits.ncols;
    ghost_lidx_t m = v->traits.ncols;
    ghost_lidx_t n = v->traits.nrows;

    INFO_LOG("In TSMM with two fixed block sizes %"PRLIDX"x%"PRLIDX" <- %"PRLIDX"x%"PRLIDX" * %"PRLIDX"x%"PRLIDX,n,k,n,m,m,k);

    const double complex * const restrict vval = (const double complex*) v->val;
    const double complex * const restrict wval = (const double complex*) w->val;
    double complex * const restrict xval = (double complex*) x->val;

    const ghost_lidx_t ldv = v->stride;
    const ghost_lidx_t ldw = w->stride;
    const ghost_lidx_t ldx = x->stride;

    const double complex dalpha = *(double complex *)alpha;
    const double complex dbeta = *(double complex *)beta;
    ghost_lidx_t i,j,s;

    double complex tmp;
    
#pragma omp parallel for private(j,s,tmp) schedule(runtime)
    for (i=0; i<n; i++) {
#if CFGK > 1
#pragma simd
#endif
        for (s=0; s<CFGK; s++) {
            tmp = dbeta*xval[i*ldx+s];
#if CFGK > 1
#pragma unroll_and_jam
#else
#if CFGM > 1
#pragma simd
#endif
#endif
            for (j=0; j<CFGM; j++) {
                tmp += dalpha*vval[i*ldv+j]*wval[j*ldw+s];
            }
            xval[i*ldx+s] = tmp;
        }
    }

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    return ret;
}
#GHOST_FUNC_END

#GHOST_FUNC_BEGIN#CFGK=${CFG_BLOCKVECTOR_SIZES}
ghost_error_t ghost_tsmm__u_plain_z_CFGK_x_1_rm_cm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    ghost_error_t ret = GHOST_SUCCESS;

    ghost_lidx_t m = v->traits.ncols;
    ghost_lidx_t n = v->traits.nrows;

    
    INFO_LOG("In TSMM with fixed K %"PRLIDX" and arbitrary M %"PRLIDX": %"PRLIDX"x%"PRLIDX" <- %"PRLIDX"x%"PRLIDX" * %"PRLIDX"x%"PRLIDX,CFGK,m,n,CFGK,n,m,m,CFGK);

    const double complex * const restrict vval = (const double complex*) v->val;
    const double complex * const restrict wval = (const double complex*) w->val;
    double complex * const restrict xval = (double complex*) x->val;

    const ghost_lidx_t ldv = v->stride;
    const ghost_lidx_t ldw = w->stride;
    const ghost_lidx_t ldx = x->stride;

    const double complex dalpha = *(double complex *)alpha;
    const double complex dbeta = *(double complex *)beta;
    ghost_lidx_t i,j,s;
    
#pragma omp parallel for private(j,s) schedule(runtime)
    for (i=0; i<n; i++) {
        for (s=0; s<CFGK; s++) {
            xval[i*ldx+s] = dbeta*xval[i*ldx+s];
#pragma simd
            for (j=0; j<m; j++) {
                xval[i*ldx+s] += dalpha*vval[i*ldv+j]*wval[s*ldw+j];
            }
        }
    }

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    return ret;
}
#GHOST_FUNC_END

#GHOST_FUNC_BEGIN#CFGM=${CFG_BLOCKVECTOR_SIZES}
ghost_error_t ghost_tsmm__u_plain_z_x_CFGM_1_rm_cm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    ghost_error_t ret = GHOST_SUCCESS;

    ghost_lidx_t k = x->traits.ncols;
    ghost_lidx_t n = v->traits.nrows;

    
    INFO_LOG("In TSMM with fixed M %"PRLIDX" and arbitrary K %"PRLIDX": %"PRLIDX"x%"PRLIDX" <- %"PRLIDX"x%"PRLIDX" * %"PRLIDX"x%"PRLIDX,CFGM,k,n,CFGM,n,k,k,CFGM);

    const double complex * const restrict vval = (const double complex*) v->val;
    const double complex * const restrict wval = (const double complex*) w->val;
    double complex * const restrict xval = (double complex*) x->val;

    const ghost_lidx_t ldv = v->stride;
    const ghost_lidx_t ldw = w->stride;
    const ghost_lidx_t ldx = x->stride;

    const double complex dalpha = *(double complex *)alpha;
    const double complex dbeta = *(double complex *)beta;
    ghost_lidx_t i,j,s;
    
#pragma omp parallel for private(j,s) schedule(runtime)
    for (i=0; i<n; i++) {
        for (s=0; s<k; s++) {
            xval[i*ldx+s] = dbeta*xval[i*ldx+s];
#pragma simd
            for (j=0; j<CFGM; j++) {
                xval[i*ldx+s] += dalpha*vval[i*ldv+j]*wval[s*ldw+j];
            }
        }
    }

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL)
    return ret;
}
#GHOST_FUNC_END
