/*!GHOST_AUTOGEN_TSMTTSM M,N */
#include "ghost/config.h"
#include "ghost/types.h"
#include "ghost/math.h"
#include "ghost/instr.h"
#include "ghost/util.h"
#include "ghost/tsmttsm_plain_gen.h"

#GHOST_SUBST CFGN ${N}
#GHOST_SUBST CFGM ${M}
#GHOST_SUBST OUTERUNROLL 2

#if 0
#GHOST_FUNC_BEGIN#CFGN=${BLOCKDIM1}#CFGM=${BLOCKDIM2}
struct dCFGNxCFGM { double v[CFGN*CFGM]; };
static void add_CFGNxCFGM(struct dCFGNxCFGM * x,struct dCFGNxCFGM * y){
      int i;
        for (i=0;i<CFGN*CFGM;i++) {
            x->v[i] += y->v[i];
        }
}
#pragma omp declare reduction(dCFGNxCFGMAdd: struct dCFGNxCFGM: \
        add_CFGNxCFGM(&omp_out,&omp_in)) initializer(\
        omp_priv={{\
#GHOST_UNROLL#0,\#CFGN*CFGM
        }} )
#GHOST_FUNC_END
#endif

ghost_error ghost_tsmttsm__u_plain_d_CFGN_CFGM_OUTERUNROLL_cm(ghost_densemat *x, ghost_densemat *v, ghost_densemat *w, void *alpha, void *beta, int conjv)
{
    UNUSED(conjv);
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH)
    ghost_error ret = GHOST_SUCCESS;

    ghost_lidx n = DM_NROWS(v);
    if (n%OUTERUNROLL) {
        n+=(OUTERUNROLL-n%OUTERUNROLL);
        INFO_LOG("Padding large dimension to %d\n",n);
    }
    INFO_LOG("In TSMTTSM with two fixed block sizes %dx%d <- %dx%d * %dx%d",CFGM,CFGN,CFGM,n,n,CFGN);
    
    double * restrict vval = (double *) v->val, * restrict wval = (double *) w->val, * restrict xval = (double *) x->val;
    ghost_lidx ldv, ldw, ldx;

    ldv = v->stride;
    ldw = w->stride;
    ldx = x->stride;

    double dalpha = *(double *)alpha;
    double dbeta = *(double *)beta;
    
    ghost_lidx i;
#if 0
    ghost_lidx j,k;
    struct dCFGNxCFGM xnopad;

    for (k=0; k<CFGN; k++) {
        for (j=0; j<CFGM; j++) {
            xnopad.v[j*CFGN+k] = 0;
        }
    }
#endif
    
#if 0
#pragma omp parallel for private(j,k) reduction(dCFGNxCFGMAdd: xnopad)
    for (i=0; i<n; i++) {
        for (j=0; j<CFGM; j++) {
            for (k=0; k<CFGN; k++) {
                xnopad.v[j*CFGN+k] += dalpha*vval[j*ldv+i]*wval[k*ldw+i];
            }
        }
    }
    for (k=0; k<CFGN; k++) {
        for (j=0; j<CFGM; j++) {
            xval[k*ldx+j] = dbeta*xval[k*ldx+j] + xnopad.v[j*CFGN+k];
        }
    }
#endif
#GHOST_UNROLL#double sum@ = 0;#CFGM*CFGN
#if 1//CFGM == 1 && CFGN == 1
#pragma omp parallel for \
#GHOST_UNROLL#reduction(+:sum@)\#CFGM*CFGN
        schedule(runtime) 
    for (i=0; i<n; i++) {
#GHOST_UNROLL#sum@ += dalpha*vval[(@/CFGN)*ldv+i]*wval[(@%CFGN)*ldw+i];#CFGM*CFGN
                    //x_priv[j*CFGN+k] += vval[j*ldv+i]*wval[k*ldw+i];
    }
#GHOST_UNROLL#xval[(@%CFGN)*ldx+(@/CFGN)] = dbeta*xval[(@%CFGN)*ldx+(@/CFGN)] + sum@;#CFGM*CFGN
//    xval[0] = sum;
   /* 
#pragma omp critical
        {
            for (k=0; k<CFGN; k++) {
                for (j=0; j<CFGM; j++) {
                    xval[k*ldx+j] += dalpha*x_priv[j*CFGN+k];
                }
            }
        }
        free(x_priv);*/
    
#else
#pragma omp parallel private(j,k)
    {
        ghost_lidx t;
        double *x_priv;
        ghost_malloc_align((void **)&x_priv,CFGM*CFGN*sizeof(double),64);
        memset(x_priv,0,CFGM*CFGN*sizeof(double));
        
#pragma omp for schedule(runtime)
        for (i=0; i<=n-OUTERUNROLL; i+=OUTERUNROLL) {
            for (j=0; j<CFGM; j++) {
                for (k=0; k<CFGN; k++) {
#pragma vector always
#pragma ivdep
#pragma simd
                  for (t=0; t<OUTERUNROLL; t++) {
                        x_priv[j*CFGN+k] += vval[j*ldv+i+t]*wval[k*ldw+i+t];
                  }
                }
            }
        }

#pragma omp critical
        {
            for (k=0; k<CFGN; k++) {
                for (j=0; j<CFGM; j++) {
                    xval[k*ldx+j] += dalpha*x_priv[j*CFGN+k];
                }
            }
        }
        free(x_priv);
    }
#endif
   
    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH)
    return ret;
}

ghost_error ghost_tsmttsm__a_plain_z_CFGN_CFGM_2_rm(ghost_densemat *x, ghost_densemat *v, ghost_densemat *w, void *alpha, void *beta, int conjv)
{
    UNUSED(conjv);
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH)
    ghost_error ret = GHOST_SUCCESS;

    ghost_lidx n = DM_NROWS(v);
    if (n%2) {
        n+=(2-n%2);
        INFO_LOG("Padding large dimension to %d\n",n);
    }
    INFO_LOG("In TSMTTSM with two fixed block sizes %dx%d <- %dx%d * %dx%d",CFGM,CFGN,CFGM,n,n,CFGN);
    
    complex double * restrict vval = (complex double *) v->val, * restrict wval = (complex double *) w->val, * restrict xval = (complex double *) x->val;
    ghost_lidx ldv, ldw, ldx;

    ldv = v->stride;
    ldw = w->stride;
    ldx = x->stride;
    
    complex double dalpha = *(complex double *)alpha;
    complex double dbeta = *(complex double *)beta;
    
    ghost_lidx i,j,k;
#if CFGN>1
#pragma simd
#endif
    for (k=0; k<CFGN; k++) {
        for (j=0; j<CFGM; j++) {
            xval[k*ldx+j] = dbeta*xval[k*ldx+j];
        }
    }
#pragma omp parallel private(j,k)
    {
        complex double * restrict x_priv;
        const ghost_lidx ldxpriv = PAD(CFGM,2);
        ghost_malloc_align((void **)&x_priv,ldxpriv*CFGN*sizeof(complex double),32);
        memset(x_priv,0,ldxpriv*CFGN*sizeof(complex double));
        complex double __attribute__((unused)) wval0,wval1;
        
        if (conjv) {
#pragma omp for schedule(runtime)
            for (i=0; i<=n-2; i+=2) {
#if CFGN<8
                #GHOST_MUNROLL
                wval0=wval[i*ldw+@]; 
                wval1=wval[(i+1)*ldw+@]; 
#pragma simd 
#pragma vector aligned
#pragma vector always
                for (j=0; j<CFGM; j++) {
                    x_priv[j+@*ldxpriv] += conj(vval[i*ldv+j])*wval0 + conj(vval[(i+1)*ldv+j])*wval1;
                }
                #GHOST_MUNROLL#CFGN
#else
#pragma unroll_and_jam(2)
                for (k=0; k<CFGN; k++) {
#pragma simd
#pragma vector aligned
#pragma vector always
#if CFGM>=8
#pragma unroll(CFGM)
#endif
                    for (j=0; j<CFGM; j++) {
                      x_priv[j+k*ldxpriv] += conj(vval[i*ldv+j])*wval[i*ldw+k] + conj(vval[(i+1)*ldv+j])*wval[(i+1)*ldw+k];
                    }
                }
#endif

            }
        } else {
#pragma omp for schedule(runtime)
            for (i=0; i<=n-2; i+=2) {
#if CFGN>=8
#pragma unroll_and_jam(2)
#endif
                for (k=0; k<CFGN; k++) {
#pragma simd
#pragma vector aligned
#pragma vector always
#if CFGM>=8
#pragma unroll(CFGM)
#endif
                  for (j=0; j<CFGM; j++) {
                        x_priv[j+k*ldxpriv] += vval[i*ldv+j]*wval[i*ldw+k] + 
                            vval[(i+1)*ldv+j]*wval[i*ldw+k];
                    }
                }

            }
        }

#pragma omp critical
        for (k=0; k<CFGN; k++) {
#pragma simd
#pragma vector aligned
#pragma vector always
            for (j=0; j<CFGM; j++) {
                xval[k*ldx+j] += dalpha*x_priv[j+k*ldxpriv];
            }
        }

        free(x_priv);
    }
   
    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH)
    return ret;
}

ghost_error ghost_tsmttsm__a_plain_d_CFGN_CFGM_2_rm(ghost_densemat *x, ghost_densemat *v, ghost_densemat *w, void *alpha, void *beta, int conjv)
{
    UNUSED(conjv);
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH)
    ghost_error ret = GHOST_SUCCESS;

    ghost_lidx n = DM_NROWS(v);
    if (n%2) {
        n+=(2-n%2);
        INFO_LOG("Padding large dimension to %d\n",n);
    }
    INFO_LOG("In TSMTTSM with two fixed block sizes %dx%d <- %dx%d * %dx%d",CFGM,CFGN,CFGM,n,n,CFGN);
    
    const double * const restrict vval = (const double *) v->val;
    const double * const restrict wval = (const double *) w->val;
    double * const restrict xval = (double *) x->val;
    ghost_lidx ldv, ldw, ldx;

    ldv = v->stride;
    ldw = w->stride;
    ldx = x->stride;

    double dalpha = *(double *)alpha;
    double dbeta = *(double *)beta;
    
    ghost_lidx i,j;
    
    ghost_lidx k;
#if CFGN>1
#pragma simd
#endif
    for (k=0; k<CFGN; k++) {
        for (j=0; j<CFGM; j++) {
            xval[k*ldx+j] = dbeta*xval[k*ldx+j];
        }
    }
#pragma omp parallel private(j,k)
    {
        double * restrict x_priv;
        const ghost_lidx ldxpriv = PAD(CFGM,4);
        ghost_malloc_align((void **)&x_priv,ldxpriv*CFGN*sizeof(double),32);
        memset(x_priv,0,ldxpriv*CFGN*sizeof(double));
#pragma omp for schedule(runtime)
        for (i=0; i<=n-2; i+=2) {
            for (k=0; k<CFGN; k++) {
#pragma simd
#pragma vector aligned
#pragma vector always
              for (j=0; j<CFGM; j++) {
                    x_priv[j+k*ldxpriv] += vval[i*ldv+j]*wval[i*ldw+k]+vval[(i+1)*ldv+j]*wval[(i+1)*ldw+k];
                }
            }

        }
#pragma omp critical
        for (k=0; k<CFGN; k++) {
#pragma simd
#pragma vector aligned
#pragma vector always
            for (j=0; j<CFGM; j++) {
                xval[k*ldx+j] += dalpha*x_priv[j+k*ldxpriv];
            }
        }
        free(x_priv);
    }
   
    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH)
    return ret;
}

ghost_error ghost_tsmttsm__a_plain_d_CFGN_CFGM_4_cm(ghost_densemat *x, ghost_densemat *v, ghost_densemat *w, void *alpha, void *beta, int conjv)
{
    UNUSED(conjv);
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH)
    ghost_error ret = GHOST_SUCCESS;

    ghost_lidx n = DM_NROWS(v);
    if (n%4) {
        n+=(4-n%4);
        INFO_LOG("Padding large dimension to %d",n);
    }
    INFO_LOG("In TSMTTSM with two fixed block sizes %dx%d <- %dx%d * %dx%d",CFGM,CFGN,CFGM,n,n,CFGN);
    
    double * restrict vval = (double *) v->val, * restrict wval = (double *) w->val, * restrict xval = (double *) x->val;
    ghost_lidx ldv, ldw, ldx;

    ldv = v->stride;
    ldw = w->stride;
    ldx = x->stride;
    
    double dalpha = *(double *)alpha;
    double dbeta = *(double *)beta;
    
    ghost_lidx i,j,t;
    
    ghost_lidx k;
    for (k=0; k<CFGN; k++) {
        for (j=0; j<CFGM; j++) {
            xval[k*ldx+j] = dbeta*xval[k*ldx+j];
        }
    }

#pragma omp parallel private(j,k,t)
    {
        double *x_priv;
        ghost_malloc_align((void **)&x_priv,CFGM*CFGN*sizeof(double),32);
        memset(x_priv,0,CFGM*CFGN*sizeof(double));
        
#pragma omp for schedule(runtime)
        for (i=0; i<=n-4; i+=4) {
            for (j=0; j<CFGM; j++) {
                for (k=0; k<CFGN; k++) {
                    double tmp = 0;
#pragma simd reduction(+:tmp)
                     for (t=0; t<4; t++) {
                           tmp += vval[j*ldv+i+t]*wval[k*ldw+i+t];
                     }
                     x_priv[j*CFGN+k] += tmp;
                }
            }
        }

#pragma omp critical
        {
            for (j=0; j<CFGM; j++) {
                for (k=0; k<CFGN; k++) {
                    xval[k*ldx+j] += dalpha*x_priv[j*CFGN+k];
                }
            }
        }
        free(x_priv);
    }
   
    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH)
    return ret;
}

