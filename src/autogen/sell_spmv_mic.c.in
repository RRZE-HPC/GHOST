/*!GHOST_AUTOGEN_SPMMV CHUNKHEIGHT,NVECS */
#include "ghost/config.h"
#include "ghost/types.h"
#include "ghost/util.h"
#include "ghost/instr.h"
#include "ghost/machine.h"
#include "ghost/omp.h"
#include "ghost/sparsemat.h"
#include "ghost/math.h"
#include "ghost/sell_spmv_mic_gen.h"

#ifndef __FUJITSU
#include <immintrin.h>
#endif

#GHOST_SUBST NVECS ${NVECS}
#GHOST_SUBST CHUNKHEIGHT ${CHUNKHEIGHT}


#ifdef GHOST_BUILD_AVX512
#define complex_broadcast(addr) _mm512_broadcast_f64x4(_mm256_broadcast_pd((__m128d *)(addr)))
#define complex_mul(a,b) _mm512_fmaddsub_pd(_mm512_shuffle_pd(b,b,0),a,_mm512_mul_pd(_mm512_shuffle_pd(b,b,0xFF),_mm512_shuffle_pd(a,a,0x55)))
#define complex_mul_noshuf(a,b) _mm512_fmaddsub_pd(b,a,_mm512_mul_pd(b,a))
#define complex_mul2(a,b_re,b_im) _mm512_fmaddsub_pd(b_re,a,_mm512_mul_pd(b_im,_mm512_swizzle_pd(a,_MM_SWIZ_REG_CDAB)))
#define STREAMINGSTORE _mm512_stream_pd
#else
#define STREAMINGSTORE _mm512_storenrngo_pd
#endif

ghost_error ghost_sellspmvSTRIPPED__a_mic_d_d_cm_CHUNKHEIGHT_NVECS(ghost_densemat *res, ghost_sparsemat *mat, ghost_densemat* invec, ghost_spmv_opts traits)
{
    UNUSED(traits);    
#if defined(GHOST_BUILD_MIC) && CHUNKHEIGHT>=16
    ghost_lidx c,j;
    ghost_lidx offs;
    double *mval = (double *)mat->val;
    __m512d val;
    __m512d rhs;
    __m512i idx;

#pragma omp parallel private(j,idx,val,rhs,offs)
    {
        #GHOST_UNROLL#__m512d tmp@;#CHUNKHEIGHT/8
#pragma omp for schedule(runtime) 
        for (c=0; c<SPM_NCHUNKS(mat); c++) {
            #GHOST_UNROLL#tmp@ = _mm512_setzero_pd();#CHUNKHEIGHT/8
            double *lval = (double *)res->val;
            double *rval = (double *)invec->val;
            offs = mat->chunkStart[c];

            for (j=0; j<mat->chunkLen[c]; j++) 
            { // loop inside chunk
                #GHOST_UNROLL#val = _mm512_load_pd(&mval[offs]);idx = _mm512_load_epi32(&mat->col[offs]);rhs = _mm512_i32logather_pd(idx,rval,8);tmp~2*@~ = _mm512_add_pd(tmp~2*@~,_mm512_mul_pd(val,rhs));offs += 8;val = _mm512_load_pd(&mval[offs]);idx = _mm512_permute4f128_epi32(idx,_MM_PERM_BADC);rhs = _mm512_i32logather_pd(idx,rval,8);tmp~2*@+1~ = _mm512_add_pd(tmp~2*@+1~,_mm512_mul_pd(val,rhs));offs += 8;#CHUNKHEIGHT/16
            }
            #GHOST_UNROLL#_mm512_store_pd(&lval[c*CHUNKHEIGHT+8*@],_mm512_add_pd(tmp@,_mm512_load_pd(&lval[c*CHUNKHEIGHT+8*@])));#CHUNKHEIGHT/8
        }
    }
#else 
    UNUSED(mat);
    UNUSED(res);
    UNUSED(invec);
    UNUSED(traits);
#endif
    return GHOST_SUCCESS;
}

ghost_error ghost_sellspmv__a_mic_d_d_cm_CHUNKHEIGHT_NVECS(ghost_densemat *res, ghost_sparsemat *mat, ghost_densemat* invec, ghost_spmv_opts traits)
{
    
#if defined(GHOST_BUILD_MIC) && CHUNKHEIGHT>=16
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL);
    ghost_lidx c,j,v,i;
    ghost_lidx offs;
    double *mval = (double *)mat->val;
    __m512d val;
    __m512d rhs;
#ifdef GHOST_BUILD_AVX512
    __m256i idx;
#else
    __m512i idx;
#endif
    double *local_dot_product = NULL;
    double *partsums = NULL;
    ghost_densemat *z = NULL;
    double sscale = 1., sbeta = 1., sdelta = 0., seta = 0.;
    double *sshift = NULL;
    __m512d shift, scale, beta;

    GHOST_SPMV_PARSE_TRAITS(traits,sscale,sbeta,sshift,local_dot_product,z,sdelta,seta,double,double);
    scale = _mm512_set1_pd(sscale);
    beta = _mm512_set1_pd(sbeta);

    int nthreads = 1;
    unsigned clsize;
    ghost_machine_cacheline_size(&clsize);
    int padding = (int)clsize/sizeof(double);
    if (traits.flags & GHOST_SPMV_DOT) {

#pragma omp parallel 
        {
#pragma omp single
            nthreads = ghost_omp_nthread();
        }

        GHOST_CALL_RETURN(ghost_malloc((void **)&partsums,(3*invec->traits.ncols+padding)*nthreads*sizeof(double))); 
        for (i=0; i<(3*invec->traits.ncols+padding)*nthreads; i++) {
            partsums[i] = 0.;
        }
    }

#pragma omp parallel private(j,idx,val,rhs,offs,v)
    {
        #GHOST_UNROLL#__m512d tmp@;#CHUNKHEIGHT/8
        int tid = ghost_omp_threadnum();
        __m512d dot1[invec->traits.ncols],dot2[invec->traits.ncols],dot3[invec->traits.ncols];
        for (v=0; v<invec->traits.ncols; v++) {
            dot1[v] = _mm512_setzero_pd();
            dot2[v] = _mm512_setzero_pd();
            dot3[v] = _mm512_setzero_pd();
        }
#pragma omp for schedule(runtime) 
        for (c=0; c<SPM_NCHUNKS(mat); c++) {
            for (v=0; v<NVECS; v++) {
                #GHOST_UNROLL#tmp@ = _mm512_setzero_pd();#CHUNKHEIGHT/8
                double *lval = (double *)res->val+v*res->stride;
                double *rval = (double *)invec->val+v*invec->stride;
                offs = mat->chunkStart[c];

                for (j=0; j<(mat->chunkStart[c+1]-mat->chunkStart[c])/CHUNKHEIGHT; j++) 
                { // loop inside chunk
#ifdef GHOST_BUILD_AVX512
                    #GHOST_UNROLL#val = _mm512_load_pd(&mval[offs]);idx = _mm256_load_si256((__m256i *)(&mat->col[offs]));rhs = _mm512_i32gather_pd(idx,rval,8); tmp@ = _mm512_fmadd_pd(val,rhs,tmp@); offs+=8;#CHUNKHEIGHT/8
#else
                    #GHOST_UNROLL#val = _mm512_load_pd(&mval[offs]);idx = _mm512_load_epi32(&mat->col[offs]);rhs = _mm512_i32logather_pd(idx,rval,8);tmp~2*@~ = _mm512_add_pd(tmp~2*@~,_mm512_mul_pd(val,rhs));offs += 8;val = _mm512_load_pd(&mval[offs]);idx = _mm512_permute4f128_epi32(idx,_MM_PERM_BADC);rhs = _mm512_i32logather_pd(idx,rval,8);tmp~2*@+1~ = _mm512_add_pd(tmp~2*@+1~,_mm512_mul_pd(val,rhs));offs += 8;#CHUNKHEIGHT/16
#endif
                }
                if (traits.flags & (GHOST_SPMV_SHIFT | GHOST_SPMV_VSHIFT)) {
                    if (traits.flags & GHOST_SPMV_SHIFT) {
                        shift = _mm512_set1_pd(sshift[0]);
                    } else {
                        shift = _mm512_set1_pd(sshift[v]);
                    }
                    #GHOST_UNROLL#tmp@ = _mm512_sub_pd(tmp@,_mm512_mul_pd(shift,_mm512_load_pd(&rval[c*CHUNKHEIGHT+8*@])));#CHUNKHEIGHT/8
                }
                if (traits.flags & GHOST_SPMV_SCALE) {
                    #GHOST_UNROLL#tmp@ = _mm512_mul_pd(scale,tmp@);#CHUNKHEIGHT/8
                }
                if (traits.flags & GHOST_SPMV_AXPY) {
                    #GHOST_UNROLL#_mm512_store_pd(&lval[c*CHUNKHEIGHT+8*@],_mm512_add_pd(tmp@,_mm512_load_pd(&lval[c*CHUNKHEIGHT+8*@])));#CHUNKHEIGHT/8
                } else if (traits.flags & GHOST_SPMV_AXPBY) {
                    #GHOST_UNROLL#_mm512_store_pd(&lval[c*CHUNKHEIGHT+8*@],_mm512_add_pd(tmp@,_mm512_mul_pd(beta,_mm512_load_pd(&lval[c*CHUNKHEIGHT+8*@]))));#CHUNKHEIGHT/8
                } else {
                    #GHOST_UNROLL#STREAMINGSTORE(&lval[c*CHUNKHEIGHT+8*@],tmp@);#CHUNKHEIGHT/8
                }
                if (traits.flags & GHOST_SPMV_DOT) {
                    if ((c+1)*CHUNKHEIGHT <= SPM_NROWS(mat)) {
                        #GHOST_UNROLL#dot1[v] = _mm512_add_pd(dot1[v],_mm512_mul_pd(_mm512_load_pd(&lval[c*CHUNKHEIGHT+8*@]),_mm512_load_pd(&lval[c*CHUNKHEIGHT+8*@])));#CHUNKHEIGHT/8
                        #GHOST_UNROLL#dot2[v] = _mm512_add_pd(dot2[v],_mm512_mul_pd(_mm512_load_pd(&rval[c*CHUNKHEIGHT+8*@]),_mm512_load_pd(&lval[c*CHUNKHEIGHT+8*@])));#CHUNKHEIGHT/8
                        #GHOST_UNROLL#dot3[v] = _mm512_add_pd(dot3[v],_mm512_mul_pd(_mm512_load_pd(&rval[c*CHUNKHEIGHT+8*@]),_mm512_load_pd(&rval[c*CHUNKHEIGHT+8*@])));#CHUNKHEIGHT/8
                    } else {
                        ghost_lidx rem;
                        for (rem=0; rem<SPM_NROWS(mat)-c*CHUNKHEIGHT; rem++) {
                            partsums[((padding+3*invec->traits.ncols)*tid)+3*v+0] += lval[c*CHUNKHEIGHT+rem]*lval[c*CHUNKHEIGHT+rem];
                            partsums[((padding+3*invec->traits.ncols)*tid)+3*v+1] += lval[c*CHUNKHEIGHT+rem]*rval[c*CHUNKHEIGHT+rem];
                            partsums[((padding+3*invec->traits.ncols)*tid)+3*v+2] += rval[c*CHUNKHEIGHT+rem]*rval[c*CHUNKHEIGHT+rem];
                        }
                    }
                }
            }
        }
        if (traits.flags & GHOST_SPMV_DOT) {
            for (v=0; v<invec->traits.ncols; v++) {
                partsums[((padding+3*invec->traits.ncols)*tid)+3*v+0] += _mm512_reduce_add_pd(dot1[v]);
                partsums[((padding+3*invec->traits.ncols)*tid)+3*v+1] += _mm512_reduce_add_pd(dot2[v]);
                partsums[((padding+3*invec->traits.ncols)*tid)+3*v+2] += _mm512_reduce_add_pd(dot3[v]);
            }
        }
    }
    if (traits.flags & GHOST_SPMV_CHAIN_AXPBY) {
        PERFWARNING_LOG("AXPBY will not be done on-the-fly!");
        ghost_axpby(z,res,&seta,&sdelta);
    }
    if (traits.flags & GHOST_SPMV_DOT) {
        for (v=0; v<invec->traits.ncols; v++) {
            local_dot_product[v                       ] = 0.; 
            local_dot_product[v  +   invec->traits.ncols] = 0.;
            local_dot_product[v  + 2*invec->traits.ncols] = 0.;
            for (i=0; i<nthreads; i++) {
                local_dot_product[v                       ] += partsums[(padding+3*invec->traits.ncols)*i + 3*v + 0];
                local_dot_product[v  +   invec->traits.ncols] += partsums[(padding+3*invec->traits.ncols)*i + 3*v + 1];
                local_dot_product[v  + 2*invec->traits.ncols] += partsums[(padding+3*invec->traits.ncols)*i + 3*v + 2];
            }
        }
        free(partsums);
    }
    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL);
#else 
    UNUSED(mat);
    UNUSED(res);
    UNUSED(invec);
    UNUSED(traits);
#endif
    return GHOST_SUCCESS;
}

ghost_error ghost_sellspmvBROKEN__a_mic_d_d_rm_CHUNKHEIGHT_NVECS(ghost_densemat *res, ghost_sparsemat *mat, ghost_densemat* invec, ghost_spmv_opts traits)
{
#if defined(GHOST_BUILD_MIC) && NVECS>=8
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL);
    double *mval = (double *)mat->val;
    double *local_dot_product = NULL;
    double *partsums = NULL;
    int nthreads = 1, i;
    
    unsigned clsize;
    ghost_machine_cacheline_size(&clsize);
    int padding = (int)clsize/sizeof(double);

    
    
    ghost_densemat *z = NULL;
    double sscale = 1., sbeta = 1., sdelta = 0., seta = 0.;
    double *sshift = NULL;
    __m512d scale, beta;

    GHOST_SPMV_PARSE_TRAITS(traits,sscale,sbeta,sshift,local_dot_product,z,sdelta,seta,double,double);
    scale = _mm512_set1_pd(sscale);
    beta = _mm512_set1_pd(sbeta);
    
    if (traits.flags & GHOST_SPMV_DOT) {

#pragma omp parallel 
        {
#pragma omp single
            nthreads = ghost_omp_nthread();
        }

        GHOST_CALL_RETURN(ghost_malloc((void **)&partsums,(3*invec->traits.ncols+padding)*nthreads*sizeof(double))); 
        ghost_lidx col;
        for (col=0; col<(3*invec->traits.ncols+padding)*nthreads; col++) {
            partsums[col] = 0.;
        }
    }

#pragma omp parallel shared (partsums)
    {
        ghost_lidx j,c,col;
        ghost_lidx offs;
        __m512d rhs;
        int tid = ghost_omp_threadnum();
        #GHOST_UNROLL#__m512d tmp@;#CHUNKHEIGHT*NVECS/8

#pragma omp for schedule(runtime)
        for (c=0; c<SPM_NCHUNKS(mat); c++) 
        { // loop over chunks
            double *lval = (double *)res->val[c*CHUNKHEIGHT];
            double *rval = (double *)invec->val[c*CHUNKHEIGHT];

            #GHOST_UNROLL#tmp@ = _mm512_setzero_pd();#CHUNKHEIGHT*NVECS/8
            offs = mat->chunkStart[c];

            for (j=0; j<mat->chunkLen[c]; j++) { // loop inside chunk
                
                #GHOST_UNROLL#rhs = _mm512_load_pd((double *)invec->val[mat->col[offs]]+(@%(NVECS/8))*8);tmp@ = _mm512_add_pd(tmp@,_mm512_mul_pd(_mm512_set1_pd(mval[offs]),rhs));if(!((@+1)%(NVECS/8)))offs++;#CHUNKHEIGHT*NVECS/8
            }
            if (traits.flags & GHOST_SPMV_SHIFT) {
                #GHOST_UNROLL#tmp@ = _mm512_sub_pd(tmp@,_mm512_mul_pd(_mm512_set1_pd(sshift[0]),_mm512_load_pd(rval+@*8)));#CHUNKHEIGHT*NVECS/8
            } else if (traits.flags & GHOST_SPMV_VSHIFT) {
                #GHOST_UNROLL#tmp@ = _mm512_sub_pd(tmp@,_mm512_mul_pd(_mm512_load_pd(&sshift[(@%(NVECS/8))*8]),_mm512_load_pd(rval+@*8)));#CHUNKHEIGHT*NVECS/8
            }
            if (traits.flags & GHOST_SPMV_SCALE) {
                #GHOST_UNROLL#tmp@ = _mm512_mul_pd(scale,tmp@);#CHUNKHEIGHT*NVECS/8
            }
            if (traits.flags & GHOST_SPMV_AXPY) {
                #GHOST_UNROLL#_mm512_store_pd(lval+@*8,_mm512_add_pd(tmp@,_mm512_load_pd(lval+@*8)));#CHUNKHEIGHT*NVECS/8
            } else if (traits.flags & GHOST_SPMV_AXPBY) {
                #GHOST_UNROLL#_mm512_store_pd(lval+@*8,_mm512_add_pd(tmp@,_mm512_mul_pd(_mm512_load_pd(lval+@*8),beta)));#CHUNKHEIGHT*NVECS/8
            } else {
                #GHOST_UNROLL#STREAMINGSTORE(lval+@*8,tmp@);#CHUNKHEIGHT*NVECS/8
            }
            if (traits.flags & GHOST_SPMV_DOT) {
                for (col = 0; col<invec->traits.ncols; col++) {
                    #GHOST_UNROLL#partsums[((padding+3*invec->traits.ncols)*tid)+3*col+0] += lval[col+@*invec->traits.ncolspadded]*lval[col+@*invec->traits.ncolspadded];#CHUNKHEIGHT
                    #GHOST_UNROLL#partsums[((padding+3*invec->traits.ncols)*tid)+3*col+1] += lval[col+@*invec->traits.ncolspadded]*rval[col+@*invec->traits.ncolspadded];#CHUNKHEIGHT
                    #GHOST_UNROLL#partsums[((padding+3*invec->traits.ncols)*tid)+3*col+2] += rval[col+@*invec->traits.ncolspadded]*rval[col+@*invec->traits.ncolspadded];#CHUNKHEIGHT
                }
            }
        }
    }
    if (traits.flags & GHOST_SPMV_CHAIN_AXPBY) {
        PERFWARNING_LOG("AXPBY will not be done on-the-fly!");
        ghost_axpby(z,res,&seta,&sdelta);
    }
    if (traits.flags & GHOST_SPMV_DOT) {
        ghost_lidx col;
        for (col=0; col<invec->traits.ncols; col++) {
            local_dot_product[col                       ] = 0.; 
            local_dot_product[col  +   invec->traits.ncols] = 0.;
            local_dot_product[col  + 2*invec->traits.ncols] = 0.;
            for (i=0; i<nthreads; i++) {
                local_dot_product[col                         ] += partsums[(padding+3*invec->traits.ncols)*i + 3*col + 0];
                local_dot_product[col  +   invec->traits.ncols] += partsums[(padding+3*invec->traits.ncols)*i + 3*col + 1];
                local_dot_product[col  + 2*invec->traits.ncols] += partsums[(padding+3*invec->traits.ncols)*i + 3*col + 2];
            }
        }
        free(partsums);
    }

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL);
#else
    UNUSED(mat);
    UNUSED(res);
    UNUSED(invec);
    UNUSED(traits);
    
#endif
    return GHOST_SUCCESS;
}

ghost_error ghost_sellspmv__a_mic_z_z_rm_CHUNKHEIGHT_NVECS(ghost_densemat *res, ghost_sparsemat *mat, ghost_densemat* invec, ghost_spmv_opts traits)
{
#if defined(GHOST_BUILD_AVX512)
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL);

#if NVECS%4
    __mmask8 mask;
#if NVECS%4 == 1
    mask = (__mmask8) _mm512_int2mask(0x3);
#endif
#if NVECS%4 == 2
    mask = (__mmask8) _mm512_int2mask(0xF);
#endif
#if NVECS%4 == 3
    mask = (__mmask8) _mm512_int2mask(0x3F);
#endif
#endif
    
    complex double *mval = (complex double *)mat->val;
    complex double *local_dot_product = NULL;
    complex double *partsums = NULL;
    int nthreads = 1, i;
    
    unsigned clsize;
    ghost_machine_cacheline_size(&clsize);
    int padding = (int)clsize/sizeof(double);

    
    
    complex double sscale = 1., sbeta = 1.;
    complex double *sshift = NULL;
    complex double sdelta = 0., seta = 0.;
    ghost_densemat *z = NULL;
    __m512d beta_re, beta_im, scale_re, scale_im;
    __m512d shift_re, shift_im, delta_re, delta_im, eta_re, eta_im;

    GHOST_SPMV_PARSE_TRAITS(traits,sscale,sbeta,sshift,local_dot_product,z,sdelta,seta,complex double,complex double);
    
    complex double *sshiftpadded = NULL;
    int sshiftcopied = 0;
    if ((traits.flags & GHOST_SPMV_VSHIFT)) {
        GHOST_CALL_RETURN(ghost_malloc_align((void **)&sshiftpadded,PAD(invec->traits.ncols,4)*sizeof(complex double),64));
        memset(sshiftpadded,0,PAD(invec->traits.ncols,4)*sizeof(complex double));
        memcpy(sshiftpadded,sshift,invec->traits.ncols*sizeof(complex double));
        sshiftcopied = 1;
    }
        
    beta_re = _mm512_set1_pd(creal(sbeta));
    beta_im = _mm512_set1_pd(cimag(sbeta));
    scale_re = _mm512_set1_pd(creal(sscale));
    scale_im = _mm512_set1_pd(cimag(sscale));
    delta_re = _mm512_set1_pd(creal(sdelta));
    delta_im = _mm512_set1_pd(cimag(sdelta));
    eta_re = _mm512_set1_pd(creal(seta));
    eta_im = _mm512_set1_pd(cimag(seta));
    shift_re = _mm512_set1_pd(creal(sshift[0]));
    shift_im = _mm512_set1_pd(cimag(sshift[0]));
    
    if (traits.flags & GHOST_SPMV_DOT) {

#pragma omp parallel 
        {
#pragma omp single
            nthreads = ghost_omp_nthread();
        }

        GHOST_CALL_RETURN(ghost_malloc((void **)&partsums,(3*PAD(invec->traits.ncols,4)+padding)*nthreads*sizeof(complex double))); 
        ghost_lidx col;
        for (col=0; col<(3*PAD(invec->traits.ncols,4)+padding)*nthreads; col++) {
            partsums[col] = 0.;
        }
    }

#pragma omp parallel shared (partsums)
    {
        ghost_lidx j,c,col;
        ghost_lidx offs;
        #GHOST_UNROLL#__m512d __attribute__((unused)) rhs@;#(NVECS+3)/4
        __m512d __attribute__((unused)) matval = _mm512_setzero_pd();
        __m512d matval_re = _mm512_setzero_pd();
        __m512d matval_im = _mm512_setzero_pd();
        int tid = ghost_omp_threadnum();
        #GHOST_UNROLL#__m512d tmp@;#(NVECS+3)/4

#pragma omp for schedule(runtime)
        for (c=0; c<SPM_NROWS(mat); c++) 
        { // loop over chunks
            complex double *lval = ((complex double *)(res->val))+res->stride*c;
            complex double *rval = ((complex double *)(invec->val))+invec->stride*c;
            complex double *zval = NULL;
            double *rhs_row;
            if (z) {
               zval = ((complex double *)(z->val))+z->stride*c;
            }
            offs = mat->chunkStart[c/CHUNKHEIGHT]+c%CHUNKHEIGHT;

            #GHOST_UNROLL#tmp@ = _mm512_setzero_pd();#(NVECS+3)/4
            
            for (j=0; j<mat->rowLen[c]; j++) { // loop inside chunk
                matval_re = _mm512_extload_pd(&mval[offs+j*CHUNKHEIGHT],_MM_UPCONV_PD_NONE,_MM_BROADCAST_1X8,_MM_HINT_NONE);
                matval_im = _mm512_extload_pd(((char *)&mval[offs+j*CHUNKHEIGHT])+sizeof(double),_MM_UPCONV_PD_NONE,_MM_BROADCAST_1X8,_MM_HINT_NONE);
                rhs_row = ((double *)(invec->val))+invec->stride*(mat->col[offs+j*CHUNKHEIGHT])*2;
                //matval_re = _mm512_set1_pd(creal(mval[offs+j*CHUNKHEIGHT]));
                //matval_im = _mm512_set1_pd(cimag(mval[offs+j*CHUNKHEIGHT]));
                /*matval = _mm512_set_pd(
                        cimag(mval[offs+j*CHUNKHEIGHT]),creal(mval[offs+j*CHUNKHEIGHT]),
                        cimag(mval[offs+j*CHUNKHEIGHT]),creal(mval[offs+j*CHUNKHEIGHT]),
                        cimag(mval[offs+j*CHUNKHEIGHT]),creal(mval[offs+j*CHUNKHEIGHT]),
                        cimag(mval[offs+j*CHUNKHEIGHT]),creal(mval[offs+j*CHUNKHEIGHT]));*/
                    
                #GHOST_UNROLL#tmp@ = _mm512_add_pd(tmp@,complex_mul2(_mm512_load_pd(rhs_row+(@*8)),matval_re,matval_im));#NVECS/4
#if NVECS%4
                matval = complex_broadcast(&(mval[offs+j*CHUNKHEIGHT]));
                rhs~NVECS/4~ = _mm512_mask_load_pd(_mm512_setzero_pd(),mask,rhs_row+((~NVECS/4~)*8));
                tmp~NVECS/4~ = _mm512_add_pd(tmp~NVECS/4~,complex_mul2(rhs~NVECS/4~,matval_re,matval_im));
#endif
            }
            if (traits.flags & GHOST_SPMV_SHIFT) {
                #GHOST_UNROLL#tmp@ = _mm512_sub_pd(tmp@,complex_mul2(_mm512_load_pd(((double *)rval)+@*8),shift_re,shift_im));#(NVECS+3)/4
            } else if (traits.flags & GHOST_SPMV_VSHIFT) {
                #GHOST_UNROLL#tmp@ = _mm512_sub_pd(tmp@,complex_mul(_mm512_load_pd(((double *)sshiftpadded)+(@*8)),_mm512_load_pd(((double *)rval)+@*8)));#(NVECS+3)/4
            }
            if (traits.flags & GHOST_SPMV_SCALE) {
                #GHOST_UNROLL#tmp@ = complex_mul2(tmp@,scale_re,scale_im);#(NVECS+3)/4
            }
            if (traits.flags & GHOST_SPMV_AXPY) {
                #GHOST_UNROLL#_mm512_store_pd(((double *)lval)+@*8,_mm512_add_pd(tmp@,_mm512_load_pd(((double *)lval)+@*8)));#NVECS/4
#if NVECS%4
                _mm512_mask_store_pd(((double *)lval)+(~NVECS/4~)*8,mask,_mm512_add_pd(tmp~NVECS/4~,_mm512_load_pd(((double *)lval)+(~NVECS/4~)*8)));
#endif
            } else if (traits.flags & GHOST_SPMV_AXPBY) {
                #GHOST_UNROLL#_mm512_store_pd(((double *)lval)+@*8,_mm512_add_pd(tmp@,complex_mul2(_mm512_load_pd(((double *)lval)+@*8),beta_re,beta_im)));#NVECS/4
#if NVECS%4
                _mm512_mask_store_pd(((double *)lval)+(~NVECS/4~)*8,mask,_mm512_add_pd(tmp~NVECS/4~,complex_mul2(_mm512_load_pd(((double *)lval)+(~NVECS/4~)*8),beta_re,beta_im)));
#endif
            } else if (traits.flags & GHOST_SPMV_CHAIN_AXPBY) {
                #GHOST_UNROLL#_mm512_store_pd(((double *)lval)+@*8,tmp@);#NVECS/4
#if NVECS%4
                _mm512_mask_store_pd(((double *)lval)+(~NVECS/4~)*8,mask,tmp~NVECS/4~);
#endif
            } else {
                #GHOST_UNROLL#STREAMINGSTORE(((double *)lval)+@*8,tmp@);#NVECS/4
#if NVECS%4
                _mm512_mask_store_pd(((double *)lval)+(~NVECS/4~)*8,mask,tmp~NVECS/4~);
#endif
            }

            if (traits.flags & GHOST_SPMV_CHAIN_AXPBY) {
                #GHOST_UNROLL#_mm512_store_pd(((double *)zval)+@*8,_mm512_add_pd(complex_mul2(_mm512_load_pd(((double *)zval)+@*8),delta_re,delta_im),complex_mul2(_mm512_load_pd(((double *)lval)+@*8),eta_re,eta_im)));#NVECS/4
#if NVECS%4
                _mm512_mask_store_pd(((double *)zval)+(~NVECS/4~)*8,mask,_mm512_add_pd(complex_mul2(_mm512_mask_load_pd(_mm512_setzero_pd(),mask,((double *)zval)+(~NVECS/4~)*8),delta_re,delta_im),complex_mul2(_mm512_mask_load_pd(_mm512_setzero_pd(),mask,((double *)lval)+(~NVECS/4~)*8),eta_re,eta_im)));
#endif
            }
            if (traits.flags & GHOST_SPMV_DOT) {
                for (col = 0; col<invec->traits.ncols; col++) {
                    partsums[((padding+3*invec->traits.ncols)*tid)+3*col+0] += conj(lval[col])*lval[col];
                    partsums[((padding+3*invec->traits.ncols)*tid)+3*col+1] += conj(lval[col])*rval[col];
                    partsums[((padding+3*invec->traits.ncols)*tid)+3*col+2] += conj(rval[col])*rval[col];
                }
            }
        }
    }
    if (traits.flags & GHOST_SPMV_DOT) {
        if (!local_dot_product) {
            WARNING_LOG("The location of the local dot products is NULL. Will not compute them!");
            return GHOST_SUCCESS;
        }
        ghost_lidx col;
        for (col=0; col<invec->traits.ncols; col++) {
            local_dot_product[col                       ] = 0.; 
            local_dot_product[col  +   invec->traits.ncols] = 0.;
            local_dot_product[col  + 2*invec->traits.ncols] = 0.;
            for (i=0; i<nthreads; i++) {
                local_dot_product[col                         ] += partsums[(padding+3*PAD(invec->traits.ncols,2))*i + 3*col + 0];
                local_dot_product[col  +   invec->traits.ncols] += partsums[(padding+3*PAD(invec->traits.ncols,2))*i + 3*col + 1];
                local_dot_product[col  + 2*invec->traits.ncols] += partsums[(padding+3*PAD(invec->traits.ncols,2))*i + 3*col + 2];
            }
        }
        free(partsums);
    }

    if (sshiftcopied) {
        free(sshiftpadded);
    }

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL);
    return GHOST_SUCCESS;
#else
    UNUSED(mat);
    UNUSED(res);
    UNUSED(invec);
    UNUSED(traits);
    
    ERROR_LOG("No AVX512 available");
    return GHOST_ERR_UNKNOWN;
#endif
}

ghost_error ghost_sellspmv__a_mic_d_d_rm_CHUNKHEIGHT_NVECS(ghost_densemat *res, ghost_sparsemat *mat, ghost_densemat* invec, ghost_spmv_opts traits)
{
#if defined(GHOST_BUILD_MIC)
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL);

#if NVECS%8
    __mmask8 mask;
#if NVECS%8 == 1
    mask = (__mmask8) _mm512_int2mask(0x1);
#endif
#if NVECS%8 == 2
    mask = (__mmask8) _mm512_int2mask(0x3);
#endif
#if NVECS%8 == 3
    mask = (__mmask8) _mm512_int2mask(0x7);
#endif
#if NVECS%8 == 4
    mask = (__mmask8) _mm512_int2mask(0xF);
#endif
#if NVECS%8 == 5
    mask = (__mmask8) _mm512_int2mask(0x1F);
#endif
#if NVECS%8 == 6
    mask = (__mmask8) _mm512_int2mask(0x3F);
#endif
#if NVECS%8 == 7
    mask = (__mmask8) _mm512_int2mask(0x7F);
#endif
#endif
    
    double *mval = (double *)mat->val;
    double *local_dot_product = NULL;
    double *partsums = NULL;
    int nthreads = 1, i;
    
    unsigned clsize;
    ghost_machine_cacheline_size(&clsize);
    int padding = (int)clsize/sizeof(double);

    
    
    double sscale = 1., sbeta = 1.;
    double *sshift = NULL;
    double sdelta = 0., seta = 0.;
    ghost_densemat *z = NULL;
    __m512d scale, beta;
    __m512d shift = _mm512_setzero_pd();
    __m512d delta = _mm512_setzero_pd();
    __m512d eta = _mm512_setzero_pd();

    GHOST_SPMV_PARSE_TRAITS(traits,sscale,sbeta,sshift,local_dot_product,z,sdelta,seta,double,double);
    
    double *sshiftpadded = NULL;
    int sshiftcopied = 0;
    if ((traits.flags & GHOST_SPMV_VSHIFT)) {
        GHOST_CALL_RETURN(ghost_malloc_align((void **)&sshiftpadded,PAD(invec->traits.ncols,4)*sizeof(double),64));
        memset(sshiftpadded,0,PAD(invec->traits.ncols,4)*sizeof(double));
        memcpy(sshiftpadded,sshift,invec->traits.ncols*sizeof(double));
        sshiftcopied = 1;
    }
        
    scale = _mm512_set1_pd(sscale);
    beta = _mm512_set1_pd(sbeta);

    if (traits.flags & GHOST_SPMV_SHIFT) {
        shift = _mm512_set1_pd(*sshift);
    }
    if (traits.flags & GHOST_SPMV_CHAIN_AXPBY) {
        delta = _mm512_set1_pd(sdelta);
        eta = _mm512_set1_pd(seta);
    }

    
    if (traits.flags & GHOST_SPMV_DOT) {

#pragma omp parallel 
        {
#pragma omp single
            nthreads = ghost_omp_nthread();
        }

        GHOST_CALL_RETURN(ghost_malloc((void **)&partsums,(3*PAD(invec->traits.ncols,8)+padding)*nthreads*sizeof(double))); 
        ghost_lidx col;
        for (col=0; col<(3*PAD(invec->traits.ncols,8)+padding)*nthreads; col++) {
            partsums[col] = 0.;
        }
    }

#pragma omp parallel shared (partsums)
    {
        ghost_lidx j,c,col;
        ghost_lidx offs;
        #GHOST_UNROLL#__m512d __attribute__((unused)) rhs@;#(NVECS+7)/8
        __m512d __attribute__((unused)) matval = _mm512_setzero_pd();
        int tid = ghost_omp_threadnum();
        #GHOST_UNROLL#__m512d tmp@;#(NVECS+7)/8

#pragma omp for schedule(runtime)
        for (c=0; c<SPM_NROWS(mat); c++) 
        { // loop over chunks
            double *lval = ((double *)(res->val))+res->stride*c;
            double *rval = ((double *)(invec->val))+invec->stride*c;
            double *zval = NULL;
            double *rhs_row;
            if (z) {
               zval = ((double *)(z->val))+z->stride*c;
            }
            offs = mat->chunkStart[c/CHUNKHEIGHT]+c%CHUNKHEIGHT;

            #GHOST_UNROLL#tmp@ = _mm512_setzero_pd();#(NVECS+7)/8
            
            for (j=0; j<mat->rowLen[c]; j++) { // loop inside chunk
                matval = _mm512_set1_pd(mval[offs+j*CHUNKHEIGHT]);
                rhs_row = ((double *)(invec->val))+invec->stride*(mat->col[offs+j*CHUNKHEIGHT]);
                #GHOST_UNROLL#tmp@ = _mm512_add_pd(tmp@,_mm512_mul_pd(_mm512_load_pd(rhs_row+(@*8)),matval));#NVECS/8
#if NVECS%8
                rhs~NVECS/8~ = _mm512_mask_load_pd(_mm512_setzero_pd(),mask,rhs_row+((~NVECS/8~)*8));
                tmp~NVECS/8~ = _mm512_add_pd(tmp~NVECS/8~,_mm512_mul_pd(rhs~NVECS/8~,matval));
#endif
            }
            if (traits.flags & GHOST_SPMV_SHIFT) {
                #GHOST_UNROLL#tmp@ = _mm512_sub_pd(tmp@,_mm512_mul_pd(_mm512_load_pd(((double *)rval)+@*8),shift));#(NVECS+7)/8
            } else if (traits.flags & GHOST_SPMV_VSHIFT) {
                #GHOST_UNROLL#tmp@ = _mm512_sub_pd(tmp@,_mm512_mul_pd(_mm512_load_pd(((double *)sshiftpadded)+(@*8)),_mm512_load_pd(((double *)rval)+@*8)));#(NVECS+7)/8
            }
            if (traits.flags & GHOST_SPMV_SCALE) {
                #GHOST_UNROLL#tmp@ = _mm512_mul_pd(tmp@,scale);#(NVECS+7)/8
            }
            if (traits.flags & GHOST_SPMV_AXPY) {
                #GHOST_UNROLL#_mm512_store_pd(((double *)lval)+@*8,_mm512_add_pd(tmp@,_mm512_load_pd(((double *)lval)+@*8)));#NVECS/8
#if NVECS%8
                _mm512_mask_store_pd(((double *)lval)+(~NVECS/8~)*8,mask,_mm512_add_pd(tmp~NVECS/8~,_mm512_load_pd(((double *)lval)+(~NVECS/8~)*8)));
#endif
            } else if (traits.flags & GHOST_SPMV_AXPBY) {
                #GHOST_UNROLL#_mm512_store_pd(((double *)lval)+@*8,_mm512_add_pd(tmp@,_mm512_mul_pd(_mm512_load_pd(((double *)lval)+@*8),beta)));#NVECS/8
#if NVECS%8
                _mm512_mask_store_pd(((double *)lval)+(~NVECS/8~)*8,mask,_mm512_add_pd(tmp~NVECS/8~,_mm512_mul_pd(_mm512_load_pd(((double *)lval)+(~NVECS/8~)*8),beta)));
#endif
            } else if (traits.flags & GHOST_SPMV_CHAIN_AXPBY) {
                #GHOST_UNROLL#_mm512_store_pd(((double *)lval)+@*8,tmp@);#NVECS/8
#if NVECS%8
                _mm512_mask_store_pd(((double *)lval)+(~NVECS/8~)*8,mask,tmp~NVECS/8~);
#endif
            } else {
                #GHOST_UNROLL#STREAMINGSTORE(((double *)lval)+@*8,tmp@);#NVECS/8
#if NVECS%8
                _mm512_mask_store_pd(((double *)lval)+(~NVECS/8~)*8,mask,tmp~NVECS/8~);
#endif
            }

            if (traits.flags & GHOST_SPMV_CHAIN_AXPBY) {
                #GHOST_UNROLL#_mm512_store_pd(((double *)zval)+@*8,_mm512_add_pd(_mm512_mul_pd(_mm512_load_pd(((double *)zval)+@*8),delta),_mm512_mul_pd(_mm512_load_pd(((double *)lval)+@*8),eta)));#NVECS/8
#if NVECS%8
                _mm512_mask_store_pd(((double *)zval)+(~NVECS/8~)*8,mask,_mm512_add_pd(_mm512_mul_pd(_mm512_mask_load_pd(_mm512_setzero_pd(),mask,((double *)zval)+(~NVECS/8~)*8),delta),_mm512_mul_pd(_mm512_mask_load_pd(_mm512_setzero_pd(),mask,((double *)lval)+(~NVECS/8~)*8),eta)));
#endif
            }
            if (traits.flags & GHOST_SPMV_DOT) {
                for (col = 0; col<invec->traits.ncols; col++) {
                    partsums[((padding+3*invec->traits.ncols)*tid)+3*col+0] += lval[col]*lval[col];
                    partsums[((padding+3*invec->traits.ncols)*tid)+3*col+1] += lval[col]*rval[col];
                    partsums[((padding+3*invec->traits.ncols)*tid)+3*col+2] += rval[col]*rval[col];
                }
            }
        }
    }
    if (traits.flags & GHOST_SPMV_DOT) {
        if (!local_dot_product) {
            WARNING_LOG("The location of the local dot products is NULL. Will not compute them!");
            return GHOST_SUCCESS;
        }
        ghost_lidx col;
        for (col=0; col<invec->traits.ncols; col++) {
            local_dot_product[col                       ] = 0.; 
            local_dot_product[col  +   invec->traits.ncols] = 0.;
            local_dot_product[col  + 2*invec->traits.ncols] = 0.;
            for (i=0; i<nthreads; i++) {
                local_dot_product[col                         ] += partsums[(padding+3*PAD(invec->traits.ncols,2))*i + 3*col + 0];
                local_dot_product[col  +   invec->traits.ncols] += partsums[(padding+3*PAD(invec->traits.ncols,2))*i + 3*col + 1];
                local_dot_product[col  + 2*invec->traits.ncols] += partsums[(padding+3*PAD(invec->traits.ncols,2))*i + 3*col + 2];
            }
        }
        free(partsums);
    }

    if (sshiftcopied) {
        free(sshiftpadded);
    }

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL);
    return GHOST_SUCCESS;
#else
    UNUSED(mat);
    UNUSED(res);
    UNUSED(invec);
    UNUSED(traits);
    
    ERROR_LOG("No MIC available");
    return GHOST_ERR_UNKNOWN;
#endif
}
