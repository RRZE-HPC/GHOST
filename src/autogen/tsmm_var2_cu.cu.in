/*!GHOST_AUTOGEN_TSMM *,* */
#include "ghost/config.h"
#include "ghost/types.h"
#include "ghost/util.h"
#include "ghost/densemat.h"
#include "ghost/log.h"
#include "ghost/timing.h"
#include "ghost/locality.h"
#include "ghost/instr.h"
#include "ghost/rand.h"
#include "ghost/tsmm_var2_cu_gen.h"

#include <cuda_runtime.h>
#include <stdio.h>
#include <cublas_v2.h>
#include <curand.h>
#include <sys/types.h>
#include <unistd.h>
#include <complex.h>

#include "ghost/cu_complex.h"
#include "ghost/math.h"

#define THREADSPERBLOCK 256

namespace {

template<typename T, typename iT, bool betaiszero>
__global__ static void ghost_tsmm_cu_rm_fallback(T *const __restrict__ x, const T *const __restrict__ v,
    const iT *const __restrict__ w, const iT alpha, const iT beta, ghost_lidx nrows,
    ghost_lidx stridex, ghost_lidx stridev, ghost_lidx stridew, const int M, const int K)
{
    int row = blockIdx.x * blockDim.y + threadIdx.y;
    int m;


    for (; row < nrows; row += gridDim.x * blockDim.y) {
        iT tmp;
        if (betaiszero) {
            zero<iT>(tmp);
        } else {
            tmp = scale<iT>((iT)x[row * stridex + threadIdx.x], beta);
        }
        for (m = 0; m < M; m++) {
            tmp = axpy<iT, iT>(tmp, alpha,
                scale<iT>((iT)__ldg(&v[row * stridev + m]), (iT)__ldg(&w[threadIdx.x * stridew + m])));
        }
        x[row * stridex + threadIdx.x] = (T)tmp;
    }
}

template<typename T, typename iT>
ghost_error tsmm_var2(ghost_densemat *x, ghost_densemat *v, ghost_densemat *w, void *alpha, void *beta)
{
    ghost_error ret = GHOST_SUCCESS;
    dim3 block, grid;
    block.x = x->traits.ncols;
    block.y = CEILDIV(THREADSPERBLOCK, block.x);
    block.z = 1;
    grid.x = CEILDIV(DM_NROWS(x), block.y);
    grid.y = 1;
    grid.z = 1;

    if (ghost_iszero(beta, w->traits.datatype)) {
        ghost_tsmm_cu_rm_fallback<T, iT, true><<<grid, block>>>((T *)x->cu_val, (T *)v->cu_val,
            (iT *)w->cu_val, *(iT *)alpha, *(iT *)beta, DM_NROWS(x), x->stride, v->stride,
            w->stride, v->traits.ncols, x->traits.ncols);
    } else {
        ghost_tsmm_cu_rm_fallback<T, iT, false><<<grid, block>>>((T *)x->cu_val, (T *)v->cu_val,
            (iT *)w->cu_val, *(iT *)alpha, *(iT *)beta, DM_NROWS(x), x->stride, v->stride,
            w->stride, v->traits.ncols, x->traits.ncols);
    }
    return ret;
}
}

ghost_error ghost_tsmm__u_cuda_x_x_x_1_1_rm(ghost_densemat *x, ghost_densemat *v, ghost_densemat *w, void *alpha, void *beta)
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH | GHOST_FUNCTYPE_KERNEL);
    ghost_error ret = GHOST_SUCCESS;


    if (x->traits.datatype & GHOST_DT_COMPLEX) {
        if (x->traits.datatype & GHOST_DT_DOUBLE) {
            tsmm_var2<cuDoubleComplex, cuDoubleComplex>(x, v, w, alpha, beta);
        } else {
            tsmm_var2<cuFloatComplex, cuFloatComplex>(x, v, w, alpha, beta);
        }
    } else {
        if (x->traits.datatype & GHOST_DT_DOUBLE && w->traits.datatype & GHOST_DT_DOUBLE) {
            tsmm_var2<double, double>(x, v, w, alpha, beta);
        } else if (x->traits.datatype & GHOST_DT_FLOAT && w->traits.datatype & GHOST_DT_FLOAT) {
            tsmm_var2<float, float>(x, v, w, alpha, beta);
        } else if (x->traits.datatype & GHOST_DT_FLOAT && w->traits.datatype & GHOST_DT_DOUBLE) {
            tsmm_var2<float, double>(x, v, w, alpha, beta);
        }
    }


    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH | GHOST_FUNCTYPE_KERNEL);
    CUDA_CALL_RETURN(cudaGetLastError());
    return ret;
}
