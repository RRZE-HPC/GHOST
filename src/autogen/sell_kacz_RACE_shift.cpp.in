/*!GHOST_AUTOGEN_KACZ 1,NVECS,NSHIFTS */
#include "ghost/config.h"
#include "ghost/types.h"
#include "ghost/util.h"
#include "ghost/instr.h"
#include "ghost/omp.h"
#include "ghost/machine.h"
#include "ghost/math.h"
#include "ghost/sparsemat.h"
#include "ghost/densemat.h"
#include "ghost/locality.h"
#include "ghost/sell_kacz_RACE_shift_gen.h"
#include <complex>
#ifdef GHOST_HAVE_RACE
#include <RACE/interface.h>
#endif
#ifndef __FUJITSU
#include <immintrin.h> 
#endif

#GHOST_SUBST NVECS ${NVECS}
#GHOST_SUBST NSHIFTS ${NSHIFTS}
#GHOST_SUBST CHUNKHEIGHT 1

#define MT double

#define VT std::complex<MT>


//#if NSHIFTS

//Fix for gcc compile error
#ifdef __GNUC__
#ifndef __INTEL_COMPILER
#define _mm256_set_m128d(va, vb) \
    _mm256_insertf128_pd(_mm256_castpd128_pd256(vb), va, 1)
#endif
#endif

#ifndef __FUJITSU
//AVX
#define complex_mul(a,b) _mm256_addsub_pd(_mm256_mul_pd(_mm256_shuffle_pd(b,b,0),a),_mm256_mul_pd(_mm256_shuffle_pd(b,b,0xF),_mm256_shuffle_pd(a,a,5)))
#define complex_mul_conj256(b,a) _mm256_addsub_pd(_mm256_mul_pd(_mm256_shuffle_pd(b,b,0),a),_mm256_mul_pd(_mm256_mul_pd(_mm256_shuffle_pd(b,b,0xF),_mm256_set1_pd(-1.)),_mm256_shuffle_pd(a,a,5)))
//SSE
#define complex_mul_128(b,a) _mm_addsub_pd(_mm_mul_pd(_mm_shuffle_pd(a,a,0), b),_mm_mul_pd(_mm_shuffle_pd(a,a,3), _mm_shuffle_pd(b,b,1))) 
#define complex_mul_conj128(b,a) _mm_addsub_pd(_mm_mul_pd(_mm_shuffle_pd(b,b,0), a),_mm_mul_pd(_mm_set1_pd(-1.),_mm_mul_pd(_mm_shuffle_pd(b,b,3), _mm_shuffle_pd(a,a,1)))) 
#endif

/*
 * //for debuging
 * void _mm256d_print(__m256d src)
 * {
 * double *dst; 
 * dst = (double *)malloc(sizeof(double)*4); 
 * __m128d a = _mm256_extractf128_pd(src, 0);
 * __m128d b = _mm256_extractf128_pd(src, 1); 
 * _mm_storel_pd(&dst[0],a);
 * _mm_storeh_pd(&dst[1],a);
 * _mm_storel_pd(&dst[2], b);
 * _mm_storeh_pd(&dst[3], b); 
 * printf("%f\t%f\t%f\t%f\n",dst[0],dst[1],dst[2],dst[3]);
 * 
 * }
 * void _mm_print(__m128d src)
 * {
 * double *dst; 
 * dst = (double *)malloc(sizeof(double)*2); 
 * _mm_storel_pd(&dst[0],src);
 * _mm_storeh_pd(&dst[1],src);
 * printf("%f\t%f\n",dst[0],dst[1]);
 * 
 * }
 */
//Solving (A-(sigma_r + i*sigma_i)I)* x = b

//undefine previous defines
#ifdef FORWARD_SHIFT_LOOP
#undef FORWARD_SHIFT_LOOP
#endif

#ifdef BACKWARD_SHIFT_LOOP
#undef BACKWARD_SHIFT_LOOP
#endif
 
#if defined(GHOST_BUILD_AVX) && (NSHIFTS%2==0 && CHUNKHEIGHT==1)

#define FORWARD_SHIFT_LOOP(start,end,MT,VT) \
for (ghost_lidx row=start; row<end; ++row){ \
#GHOST_UNROLL#__m128d rownorm@ = _mm_setzero_pd();\#(NSHIFTS/2) \
#GHOST_UNROLL#__m256d scal@ = _mm256_setzero_pd();\#((2*NSHIFTS*NVECS)/4) \
#GHOST_UNROLL#__m256d mval_sigma@ = _mm256_setzero_pd();\#(2*NSHIFTS/4) \
    __m256d xval_vec, mval_idx; \
    __m256d mval_diag = _mm256_setzero_pd(); \
    __m128d zero=_mm_setzero_pd(); \
    __m256d zero_256=_mm256_setzero_pd(); \
    __m256d temp1; \
    __m128d templo_1, temphi_1, templo_2, mval_idx_128; \
    __m256d omega_vec; \
    ghost_lidx idx = mat->chunkStart[row]; \
    if(bval != NULL) { \
#GHOST_UNROLL#templo_1 =_mm_loadl_pd (zero, &bval[row*num_blocks+~2*@%NVECS~]); templo_2 =_mm_loadl_pd (zero, &bval[row*num_blocks+~(2*@+1)%NVECS~]);scal@=_mm256_set_m128d(templo_2,templo_1);\#(NVECS*NSHIFTS)/2 \
    } \
    ghost_lidx diag_idx = 0; \
    \
    if(mat->context->row_map->loc_perm != mat->context->col_map->loc_perm) { \
        diag_idx = mat->context->col_map->loc_perm[mat->context->row_map->loc_perm_inv[row]]; \
    } \
    else { \
        diag_idx = row; \
    }\
    ghost_lidx j = 0; \
    for(j=0; j<mat->rowLen[row] && mat->col[idx+j]!=diag_idx; ++j) { \
        mval_idx_128 = _mm_set1_pd(mval[idx+j]); \
        mval_idx = _mm256_set_m128d(mval_idx_128, mval_idx_128); \
        ghost_lidx col_idx = 2*mat->col[idx+j]; /* mul 2 since double*/ \
#GHOST_UNROLL#xval_vec = _mm256_loadu_pd(&xval[col_idx*NVECS*NSHIFTS + ~4*@~]); scal@ = _mm256_sub_pd(scal@,_mm256_mul_pd(mval_idx,xval_vec));\#(NVECS*NSHIFTS)/2\
#GHOST_UNROLL#rownorm@ = _mm_add_pd (rownorm@, _mm_mul_pd(mval_idx_128, mval_idx_128));\#NSHIFTS/2 \
        /*TODO check making it double and later broadcasting*/\
    } \
    if(j!=mat->rowLen[row]) { \
        mval_diag = _mm256_setr_pd(mval[idx+j],0,mval[idx+j],0); \
    } \
    diag_idx = 2*diag_idx; /* mul 2 since complex to double*/ \
#GHOST_UNROLL#mval_sigma@ =_mm256_add_pd(mval_diag,_mm256_sub_pd(zero_256,_mm256_loadu_pd(&sigma[~4*@~])));\#NSHIFTS/2\
#GHOST_UNROLL#templo_1 = (~((2*@)/NVECS)~ & 1)?_mm256_extractf128_pd(mval_sigma~(2*@)/(2*NVECS)~,1):_mm256_extractf128_pd(mval_sigma~(2*@)/(2*NVECS)~,0);temphi_1=(~(2*@+1)/(NVECS)~ & 1)?_mm256_extractf128_pd(mval_sigma~(2*@+1)/(2*NVECS)~,1):_mm256_extractf128_pd(mval_sigma~(2*@+1)/(2*NVECS)~,0); xval_vec = _mm256_loadu_pd(&xval[diag_idx*NVECS*NSHIFTS + ~4*@~]); scal@ = _mm256_sub_pd(scal@,complex_mul(_mm256_set_m128d(temphi_1,templo_1),xval_vec));\#(NVECS*NSHIFTS)/2 \
#GHOST_UNROLL#temp1 = complex_mul_conj256(mval_sigma~@~,mval_sigma~@~); templo_1 =_mm256_extractf128_pd(temp1, 0); temphi_1 =_mm_permute_pd(_mm256_extractf128_pd(temp1, 1),1); rownorm@ = _mm_add_pd(rownorm@,_mm_add_pd (templo_1, temphi_1));\#NSHIFTS/2 \
    \
    for(int k=j+1; k<mat->rowLen[row]; ++k) { \
        mval_idx_128 = _mm_set1_pd(mval[idx+k]); \
        mval_idx = _mm256_set_m128d(mval_idx_128, mval_idx_128) ; \
        ghost_lidx col_idx = 2*mat->col[idx+k]; /* mul 2 since double*/ \
#GHOST_UNROLL#xval_vec = _mm256_loadu_pd(&xval[col_idx*NVECS*NSHIFTS + ~4*@~]); scal@ = _mm256_sub_pd (scal@,_mm256_mul_pd(mval_idx,xval_vec));\#(NVECS*NSHIFTS)/2\
#GHOST_UNROLL#rownorm@ = _mm_add_pd (rownorm@, _mm_mul_pd(mval_idx_128, mval_idx_128));\#NSHIFTS/2 \
        /*TODO check making it double and later broadcasting*/\
    } \
    omega_vec = _mm256_broadcast_sd(&omega); \
#GHOST_UNROLL#templo_1 = (~((2*@)/NVECS)~ & 1)?_mm_unpackhi_pd(rownorm~(2*@)/(2*NVECS)~, rownorm~(2*@)/(2*NVECS)~):_mm_movedup_pd (rownorm~(2*@)/(2*NVECS)~); temphi_1 = (~(2*@+1)/(NVECS)~ & 1)?_mm_unpackhi_pd(rownorm~(2*@+1)/(2*NVECS)~, rownorm~(2*@+1)/(2*NVECS)~):_mm_movedup_pd (rownorm~(2*@+1)/(2*NVECS)~);scal@ =_mm256_div_pd( _mm256_mul_pd(scal@,omega_vec),_mm256_set_m128d(temphi_1,templo_1));\#(NSHIFTS*NVECS)/2\
    \
    for(j=0; j<mat->rowLen[row]; j++) { \
        mval_idx = _mm256_broadcast_sd (&mval[idx+j]); \
        ghost_lidx col_idx = 2*mat->col[idx+j]; \
#GHOST_UNROLL#xval_vec = _mm256_loadu_pd(&xval[col_idx*NVECS*NSHIFTS + ~4*@~]); xval_vec = _mm256_add_pd(xval_vec, _mm256_mul_pd(scal@, mval_idx)); _mm256_storeu_pd (&xval[col_idx*NVECS*NSHIFTS + ~4*@~], xval_vec);\#(NSHIFTS*NVECS)/2 \
    } \
    \
#GHOST_UNROLL#mval_sigma@ = _mm256_sub_pd(zero_256,_mm256_loadu_pd(&sigma[~4*@~]));\#NSHIFTS/2 \
#GHOST_UNROLL#templo_1 = (~((2*@)/NVECS)~ & 1)?_mm256_extractf128_pd(mval_sigma~(2*@)/(2*NVECS)~,1):_mm256_extractf128_pd(mval_sigma~(2*@)/(2*NVECS)~,0);temphi_1=(~(2*@+1)/(NVECS)~ & 1)?_mm256_extractf128_pd(mval_sigma~(2*@+1)/(2*NVECS)~,1):_mm256_extractf128_pd(mval_sigma~(2*@+1)/(2*NVECS)~,0); xval_vec = _mm256_loadu_pd(&xval[diag_idx*NVECS*NSHIFTS + ~4*@~]); xval_vec = _mm256_add_pd(xval_vec,complex_mul_conj256(_mm256_set_m128d(temphi_1,templo_1), scal~@~)); _mm256_storeu_pd(&xval[diag_idx*NVECS*NSHIFTS + ~4*@~], xval_vec);\#(NSHIFTS*NVECS)/2 \
}



#define BACKWARD_SHIFT_LOOP(start,end,MT,VT) \
for (ghost_lidx row=(end-1); row>=start; --row){ \
#GHOST_UNROLL#__m128d rownorm@ = _mm_setzero_pd();\#(NSHIFTS/2) \
#GHOST_UNROLL#__m256d scal@ = _mm256_setzero_pd();\#((2*NSHIFTS*NVECS)/4) \
#GHOST_UNROLL#__m256d mval_sigma@ = _mm256_setzero_pd();\#(2*NSHIFTS/4) \
    __m256d xval_vec, mval_idx; \
    __m256d mval_diag = _mm256_setzero_pd(); \
    __m128d zero=_mm_setzero_pd(); \
    __m256d zero_256=_mm256_setzero_pd(); \
    __m256d temp1; \
    __m128d templo_1, temphi_1, templo_2, mval_idx_128; \
    __m256d omega_vec; \
    ghost_lidx idx = mat->chunkStart[row]; \
    if(bval != NULL) { \
#GHOST_UNROLL#templo_1 =_mm_loadl_pd (zero, &bval[row*num_blocks+~2*@%NVECS~]); templo_2 =_mm_loadl_pd (zero, &bval[row*num_blocks+~(2*@+1)%NVECS~]);scal@=_mm256_set_m128d(templo_2,templo_1);\#(NVECS*NSHIFTS)/2 \
    } \
    ghost_lidx diag_idx = 0; \
    \
    if(mat->context->row_map->loc_perm != mat->context->col_map->loc_perm) { \
        diag_idx = mat->context->col_map->loc_perm[mat->context->row_map->loc_perm_inv[row]]; \
    }\
    else { \
        diag_idx = row; \
    } \
    ghost_lidx j = 0; \
    for(j=0; j<mat->rowLen[row] && mat->col[idx+j]!=diag_idx; ++j) { \
        mval_idx_128 = _mm_set1_pd(mval[idx+j]); \
        mval_idx = _mm256_set_m128d(mval_idx_128, mval_idx_128); \
        ghost_lidx col_idx = 2*mat->col[idx+j]; /* mul 2 since double*/ \
#GHOST_UNROLL#xval_vec = _mm256_loadu_pd(&xval[col_idx*NVECS*NSHIFTS + ~4*@~]); scal@ = _mm256_sub_pd (scal@,_mm256_mul_pd(mval_idx,xval_vec));\#(NVECS*NSHIFTS)/2\
#GHOST_UNROLL#rownorm@ = _mm_add_pd (rownorm@, _mm_mul_pd(mval_idx_128, mval_idx_128));\#NSHIFTS/2 \
        /*TODO check making it double and later broadcasting*/\
    } \
    if(j!=mat->rowLen[row]) { \
        mval_diag = _mm256_setr_pd(mval[idx+j],0,mval[idx+j],0); \
    } \
    diag_idx = 2*diag_idx; /* mul 2 since complex to double*/ \
#GHOST_UNROLL#mval_sigma@ =_mm256_add_pd(mval_diag,_mm256_sub_pd(zero_256,_mm256_loadu_pd(&sigma[~4*@~])));\#NSHIFTS/2\
#GHOST_UNROLL#templo_1 = (~((2*@)/NVECS)~ & 1)?_mm256_extractf128_pd(mval_sigma~(2*@)/(2*NVECS)~,1):_mm256_extractf128_pd(mval_sigma~(2*@)/(2*NVECS)~,0);temphi_1=(~(2*@+1)/(NVECS)~ & 1)?_mm256_extractf128_pd(mval_sigma~(2*@+1)/(2*NVECS)~,1):_mm256_extractf128_pd(mval_sigma~(2*@+1)/(2*NVECS)~,0); xval_vec = _mm256_loadu_pd(&xval[diag_idx*NVECS*NSHIFTS + ~4*@~]); scal@ = _mm256_sub_pd(scal@,complex_mul(_mm256_set_m128d(temphi_1,templo_1),xval_vec));\#(NVECS*NSHIFTS)/2 \
#GHOST_UNROLL#temp1 = complex_mul_conj256(mval_sigma~@~,mval_sigma~@~); templo_1 =_mm256_extractf128_pd(temp1, 0); temphi_1 =_mm_permute_pd(_mm256_extractf128_pd(temp1, 1),1); rownorm@ = _mm_add_pd(rownorm@,_mm_add_pd (templo_1, temphi_1));\#NSHIFTS/2 \
    \
    for(int k=j+1; k<mat->rowLen[row]; ++k) { \
        mval_idx_128 = _mm_set1_pd(mval[idx+k]); \
        mval_idx = _mm256_set_m128d(mval_idx_128, mval_idx_128) ; \
        ghost_lidx col_idx = 2*mat->col[idx+k]; /* mul 2 since double*/ \
#GHOST_UNROLL#xval_vec = _mm256_loadu_pd(&xval[col_idx*NVECS*NSHIFTS + ~4*@~]); scal@ = _mm256_sub_pd (scal@,_mm256_mul_pd(mval_idx,xval_vec));\#(NVECS*NSHIFTS)/2\
#GHOST_UNROLL#rownorm@ = _mm_add_pd (rownorm@, _mm_mul_pd(mval_idx_128, mval_idx_128));\#NSHIFTS/2 \
        /*TODO check making it double and later broadcasting*/\
    } \
    omega_vec = _mm256_broadcast_sd(&omega); \
#GHOST_UNROLL#templo_1 = (~((2*@)/NVECS)~ & 1)?_mm_unpackhi_pd(rownorm~(2*@)/(2*NVECS)~, rownorm~(2*@)/(2*NVECS)~):_mm_movedup_pd (rownorm~(2*@)/(2*NVECS)~); temphi_1 = (~(2*@+1)/(NVECS)~ & 1)?_mm_unpackhi_pd(rownorm~(2*@+1)/(2*NVECS)~, rownorm~(2*@+1)/(2*NVECS)~):_mm_movedup_pd (rownorm~(2*@+1)/(2*NVECS)~);scal@ =_mm256_div_pd( _mm256_mul_pd(scal@,omega_vec),_mm256_set_m128d(temphi_1,templo_1));\#(NSHIFTS*NVECS)/2\
    \
    for(j=0; j<mat->rowLen[row]; j++) { \
        mval_idx = _mm256_broadcast_sd (&mval[idx+j]); \
        ghost_lidx col_idx = 2*mat->col[idx+j]; \
#GHOST_UNROLL#xval_vec = _mm256_loadu_pd(&xval[col_idx*NVECS*NSHIFTS + ~4*@~]); xval_vec = _mm256_add_pd(xval_vec, _mm256_mul_pd(scal@, mval_idx)); _mm256_storeu_pd (&xval[col_idx*NVECS*NSHIFTS + ~4*@~], xval_vec);\#(NSHIFTS*NVECS)/2 \
    } \
#GHOST_UNROLL#mval_sigma@ = _mm256_sub_pd(zero_256,_mm256_loadu_pd(&sigma[~4*@~]));\#NSHIFTS/2 \
#GHOST_UNROLL#templo_1 = (~((2*@)/NVECS)~ & 1)?_mm256_extractf128_pd(mval_sigma~(2*@)/(2*NVECS)~,1):_mm256_extractf128_pd(mval_sigma~(2*@)/(2*NVECS)~,0);temphi_1=(~(2*@+1)/(NVECS)~ & 1)?_mm256_extractf128_pd(mval_sigma~(2*@+1)/(2*NVECS)~,1):_mm256_extractf128_pd(mval_sigma~(2*@+1)/(2*NVECS)~,0); xval_vec = _mm256_loadu_pd(&xval[diag_idx*NVECS*NSHIFTS + ~4*@~]); xval_vec = _mm256_add_pd(xval_vec,complex_mul_conj256(_mm256_set_m128d(temphi_1,templo_1), scal~@~)); _mm256_storeu_pd(&xval[diag_idx*NVECS*NSHIFTS + ~4*@~], xval_vec);\#(NSHIFTS*NVECS)/2 \
}


#elif defined(GHOST_BUILD_AVX) && (NVECS%2==0 && CHUNKHEIGHT==1)

#define FORWARD_SHIFT_LOOP(start,end,MT,VT) \
for (ghost_lidx row=start; row<end; ++row){ \
#GHOST_UNROLL#double rownorm@ = 0;\#(NSHIFTS) \
#GHOST_UNROLL#__m256d scal@ = _mm256_setzero_pd();\#((2*NSHIFTS*NVECS)/4) \
#GHOST_UNROLL#__m128d mval_sigma@ = _mm_setzero_pd();\#(2*NSHIFTS/2) \
    __m256d xval_vec,mval_idx; \
    __m128d mval_diag = _mm_setzero_pd(); \
    __m128d zero=_mm_setzero_pd(); \
    __m128d templo_1, temphi_1, templo_2; \
    __m256d omega_vec; \
    double mval_idx_64; \
    ghost_lidx idx = mat->chunkStart[row]; \
    if(bval != NULL) { \
#GHOST_UNROLL#templo_1 =_mm_loadl_pd (zero, &bval[row*num_blocks+~2*@%NVECS~]); templo_2 =_mm_loadl_pd (zero, &bval[row*num_blocks+~(2*@+1)%NVECS~]);scal@=_mm256_set_m128d(templo_2,templo_1);\#(NVECS*NSHIFTS)/2 \
    } \
    ghost_lidx diag_idx = 0; \
    \
    if(mat->context->row_map->loc_perm != mat->context->col_map->loc_perm) { \
        diag_idx = mat->context->col_map->loc_perm[mat->context->row_map->loc_perm_inv[row]]; \
    } \
    else { \
        diag_idx = row; \
    } \
    ghost_lidx j = 0; \
    for(j=0; j<mat->rowLen[row] && mat->col[idx+j]!=diag_idx; ++j) { \
        mval_idx_64 = mval[idx+j]; \
        mval_idx = _mm256_set1_pd(mval_idx_64); \
        ghost_lidx col_idx = 2*mat->col[idx+j]; /* mul 2 since double*/ \
#GHOST_UNROLL#xval_vec = _mm256_loadu_pd(&xval[col_idx*NVECS*NSHIFTS + ~4*@~]); scal@ = _mm256_sub_pd (scal@,_mm256_mul_pd(mval_idx,xval_vec));\#(NVECS*NSHIFTS)/2\
#GHOST_UNROLL#rownorm@ += mval_idx_64*mval_idx_64;\#NSHIFTS \
    } \
    if(j!=mat->rowLen[row]) { \
        mval_diag = _mm_setr_pd(mval[idx+j],0); \
    } \
    diag_idx = 2*diag_idx; /* mul 2 since complex to double*/ \
#GHOST_UNROLL#mval_sigma@ =_mm_add_pd(mval_diag,_mm_sub_pd(zero,_mm_loadu_pd(&sigma[~2*@~])));\#NSHIFTS\
#GHOST_UNROLL#templo_1 = mval_sigma~((2*@)/NVECS)~; temphi_1=mval_sigma~(2*@+1)/(NVECS)~; xval_vec = _mm256_loadu_pd(&xval[diag_idx*NVECS*NSHIFTS + ~4*@~]); scal@ = _mm256_sub_pd(scal@,complex_mul(_mm256_set_m128d(temphi_1,templo_1),xval_vec));\#(NVECS*NSHIFTS)/2 \
#GHOST_UNROLL#templo_1 = complex_mul_conj128(mval_sigma~@~,mval_sigma~@~); rownorm@ += _mm_cvtsd_f64(templo_1);\#NSHIFTS\
    \
    for(int k=j+1; k<mat->rowLen[row]; ++k) { \
        mval_idx_64 = mval[idx+k]; \
        mval_idx = _mm256_set1_pd(mval_idx_64); \
        ghost_lidx col_idx = 2*mat->col[idx+k]; /* mul 2 since double*/ \
#GHOST_UNROLL#xval_vec = _mm256_loadu_pd(&xval[col_idx*NVECS*NSHIFTS + ~4*@~]); scal@ = _mm256_sub_pd (scal@,_mm256_mul_pd(mval_idx,xval_vec));\#(NVECS*NSHIFTS)/2\
#GHOST_UNROLL#rownorm@ += mval_idx_64*mval_idx_64;\#NSHIFTS \
    } \
    omega_vec = _mm256_broadcast_sd(&omega); \
#GHOST_UNROLL#templo_1 = _mm_set1_pd (rownorm~((2*@)/NVECS)~); temphi_1 = _mm_set1_pd (rownorm~(2*@+1)/(NVECS)~) ;scal@ =_mm256_div_pd( _mm256_mul_pd(scal@,omega_vec),_mm256_set_m128d(temphi_1,templo_1));\#(NSHIFTS*NVECS)/2\
    \
    for(j=0; j<mat->rowLen[row]; j++) { \
        mval_idx = _mm256_broadcast_sd (&mval[idx+j]); \
        ghost_lidx col_idx = 2*mat->col[idx+j]; \
#GHOST_UNROLL#xval_vec = _mm256_loadu_pd(&xval[col_idx*NVECS*NSHIFTS + ~4*@~]); xval_vec = _mm256_add_pd(xval_vec, _mm256_mul_pd(scal@, mval_idx)); _mm256_storeu_pd (&xval[col_idx*NVECS*NSHIFTS + ~4*@~], xval_vec);\#(NSHIFTS*NVECS)/2 \
    } \
#GHOST_UNROLL#mval_sigma@ = _mm_sub_pd(zero,_mm_loadu_pd(&sigma[~2*@~]));\#NSHIFTS \
#GHOST_UNROLL#templo_1 = mval_sigma~((2*@)/NVECS)~ ;temphi_1=mval_sigma~(2*@+1)/(NVECS)~; xval_vec = _mm256_loadu_pd(&xval[diag_idx*NVECS*NSHIFTS + ~4*@~]); xval_vec = _mm256_add_pd(xval_vec,complex_mul_conj256(_mm256_set_m128d(temphi_1,templo_1), scal~@~)); _mm256_storeu_pd(&xval[diag_idx*NVECS*NSHIFTS + ~4*@~], xval_vec);\#(NSHIFTS*NVECS)/2 \
}

#define BACKWARD_SHIFT_LOOP(start,end,MT,VT) \
for (ghost_lidx row=end-1; row>=start; --row){ \
#GHOST_UNROLL#double rownorm@ = 0;\#(NSHIFTS) \
#GHOST_UNROLL#__m256d scal@ = _mm256_setzero_pd();\#((2*NSHIFTS*NVECS)/4) \
#GHOST_UNROLL#__m128d mval_sigma@ = _mm_setzero_pd();\#(2*NSHIFTS/2) \
    __m256d xval_vec,mval_idx; \
    __m128d mval_diag = _mm_setzero_pd(); \
    __m128d zero=_mm_setzero_pd(); \
    __m128d templo_1, temphi_1, templo_2; \
    __m256d omega_vec; \
    double mval_idx_64; \
    ghost_lidx idx = mat->chunkStart[row]; \
    if(bval != NULL) { \
#GHOST_UNROLL#templo_1 =_mm_loadl_pd (zero, &bval[row*num_blocks+~2*@%NVECS~]); templo_2 =_mm_loadl_pd (zero, &bval[row*num_blocks+~(2*@+1)%NVECS~]);scal@=_mm256_set_m128d(templo_2,templo_1);\#(NVECS*NSHIFTS)/2 \
    } \
    ghost_lidx diag_idx = 0; \
    \
    if(mat->context->row_map->loc_perm != mat->context->col_map->loc_perm) { \
        diag_idx = mat->context->col_map->loc_perm[mat->context->row_map->loc_perm_inv[row]]; \
    } \
    else { \
        diag_idx = row; \
    } \
    ghost_lidx j = 0; \
    for(j=0; j<mat->rowLen[row] && mat->col[idx+j]!=diag_idx; ++j) { \
        mval_idx_64 = mval[idx+j]; \
        mval_idx = _mm256_set1_pd(mval_idx_64); \
        ghost_lidx col_idx = 2*mat->col[idx+j]; /* mul 2 since double*/ \
#GHOST_UNROLL#xval_vec = _mm256_loadu_pd(&xval[col_idx*NVECS*NSHIFTS + ~4*@~]); scal@ = _mm256_sub_pd (scal@,_mm256_mul_pd(mval_idx,xval_vec));\#(NVECS*NSHIFTS)/2\
#GHOST_UNROLL#rownorm@ += mval_idx_64*mval_idx_64;\#NSHIFTS \
    } \
    if(j!=mat->rowLen[row]) { \
        mval_diag = _mm_setr_pd(mval[idx+j],0); \
    } \
    diag_idx = 2*diag_idx; /* mul 2 since complex to double*/ \
#GHOST_UNROLL#mval_sigma@ =_mm_add_pd(mval_diag,_mm_sub_pd(zero,_mm_loadu_pd(&sigma[~2*@~])));\#NSHIFTS\
#GHOST_UNROLL#templo_1 = mval_sigma~((2*@)/NVECS)~; temphi_1=mval_sigma~(2*@+1)/(NVECS)~; xval_vec = _mm256_loadu_pd(&xval[diag_idx*NVECS*NSHIFTS + ~4*@~]); scal@ = _mm256_sub_pd(scal@,complex_mul(_mm256_set_m128d(temphi_1,templo_1),xval_vec));\#(NVECS*NSHIFTS)/2 \
#GHOST_UNROLL#templo_1 = complex_mul_conj128(mval_sigma~@~,mval_sigma~@~); rownorm@ += _mm_cvtsd_f64(templo_1);\#NSHIFTS\
    \
    for(int k=j+1; k<mat->rowLen[row]; ++k) { \
        mval_idx_64 = mval[idx+k]; \
        mval_idx = _mm256_set1_pd(mval_idx_64); \
        ghost_lidx col_idx = 2*mat->col[idx+k]; /* mul 2 since double*/ \
#GHOST_UNROLL#xval_vec = _mm256_loadu_pd(&xval[col_idx*NVECS*NSHIFTS + ~4*@~]); scal@ = _mm256_sub_pd (scal@,_mm256_mul_pd(mval_idx,xval_vec));\#(NVECS*NSHIFTS)/2\
#GHOST_UNROLL#rownorm@ += mval_idx_64*mval_idx_64;\#NSHIFTS \
    } \
    omega_vec = _mm256_broadcast_sd(&omega); \
#GHOST_UNROLL#templo_1 = _mm_set1_pd (rownorm~((2*@)/NVECS)~); temphi_1 = _mm_set1_pd (rownorm~(2*@+1)/(NVECS)~) ;scal@ =_mm256_div_pd( _mm256_mul_pd(scal@,omega_vec),_mm256_set_m128d(temphi_1,templo_1));\#(NSHIFTS*NVECS)/2\
    \
    for(j=0; j<mat->rowLen[row]; j++) { \
        mval_idx = _mm256_broadcast_sd (&mval[idx+j]); \
        ghost_lidx col_idx = 2*mat->col[idx+j]; \
#GHOST_UNROLL#xval_vec = _mm256_loadu_pd(&xval[col_idx*NVECS*NSHIFTS + ~4*@~]); xval_vec = _mm256_add_pd(xval_vec, _mm256_mul_pd(scal@, mval_idx)); _mm256_storeu_pd (&xval[col_idx*NVECS*NSHIFTS + ~4*@~], xval_vec);\#(NSHIFTS*NVECS)/2 \
    } \
#GHOST_UNROLL#mval_sigma@ = _mm_sub_pd(zero,_mm_loadu_pd(&sigma[~2*@~]));\#NSHIFTS \
#GHOST_UNROLL#templo_1 = mval_sigma~((2*@)/NVECS)~ ;temphi_1=mval_sigma~(2*@+1)/(NVECS)~; xval_vec = _mm256_loadu_pd(&xval[diag_idx*NVECS*NSHIFTS + ~4*@~]); xval_vec = _mm256_add_pd(xval_vec,complex_mul_conj256(_mm256_set_m128d(temphi_1,templo_1), scal~@~)); _mm256_storeu_pd(&xval[diag_idx*NVECS*NSHIFTS + ~4*@~], xval_vec);\#(NSHIFTS*NVECS)/2 \
}


#elif CHUNKHEIGHT==1

#define FORWARD_SHIFT_LOOP(start,end,MT,VT) \
for (ghost_lidx row=start; row<end; ++row){ \
#GHOST_UNROLL#double rownorm@ = 0;\#NSHIFTS \
#GHOST_UNROLL#double scal_@ = 0;\#2*NSHIFTS*NVECS \
#GHOST_UNROLL#double rp@ = 0;\#NSHIFTS \
#GHOST_UNROLL#double ip@ = 0;\#NSHIFTS \
    \
    double rp_x=0, ip_x=0; \
    double mval_diag = 0; \
    ghost_lidx idx = mat->chunkStart[row]; \
    if(bval != NULL) { \
#GHOST_UNROLL#scal_~(2*@)~ = bval[row*num_blocks+~@%NVECS~];\#NVECS*NSHIFTS \
    } \
    ghost_lidx diag_idx = 0; \
    \
    if(mat->context->row_map->loc_perm != mat->context->col_map->loc_perm) { \
        diag_idx = mat->context->col_map->loc_perm[mat->context->row_map->loc_perm_inv[row]]; \
    } \
    else { \
        diag_idx = row; \
    } \
    ghost_lidx j = 0; \
    for(j=0; j<mat->rowLen[row] && mat->col[idx+j]!=diag_idx; ++j) { \
        MT mval_idx = mval[idx+j]; \
        ghost_lidx col_idx = mat->col[idx+j]; \
#GHOST_UNROLL#scal_@ -= mval_idx*xval[2*col_idx*NVECS*NSHIFTS + @];\#2*NSHIFTS*NVECS \
#GHOST_UNROLL#rownorm@ += mval_idx * mval_idx;\#NSHIFTS \
    } \
    if(j!=mat->rowLen[row]) { \
        mval_diag = mval[idx+j]; \
        diag_idx = diag_idx; \
    } \
    \
#GHOST_UNROLL#rp@ = mval_diag-sigma[2*@];\#NSHIFTS \
#GHOST_UNROLL#ip@ = -sigma[2*@+1];\#NSHIFTS \
#GHOST_UNROLL#rp_x = xval[2*(diag_idx*NVECS*NSHIFTS + @)]; ip_x = xval[2*(diag_idx*NVECS*NSHIFTS + @)+1]; scal_~(2*@)~ += -rp~@/NVECS~*rp_x + ip~@/NVECS~*ip_x; scal_~(2*@+1)~ += -rp~@/NVECS~*ip_x - ip~@/NVECS~*rp_x;\#NSHIFTS*NVECS \
#GHOST_UNROLL#rownorm@ += rp~@~*rp~@~ + ip~@~*ip~@~;\#NSHIFTS \
    \
    for(int k=j+1; k<mat->rowLen[row]; ++k) { \
        MT mval_idx = mval[idx+k]; \
        ghost_lidx col_idx = mat->col[idx+k]; \
#GHOST_UNROLL#scal_@ -= mval_idx*xval[2*col_idx*NVECS*NSHIFTS + @];\#2*NSHIFTS*NVECS \
#GHOST_UNROLL#rownorm@ += mval_idx * mval_idx;\#NSHIFTS \
    } \
    \
#GHOST_UNROLL#scal_@ = (scal_@*omega)/rownorm~(@/(2*NVECS))~;\#2*NSHIFTS*NVECS \
    \
    for (j=0; j<mat->rowLen[row]; j++) { \
        MT mval_idx = mval[idx+j]; \
        ghost_lidx col_idx = mat->col[idx+j]; \
#GHOST_UNROLL#xval[2*col_idx*NVECS*NSHIFTS + @] = xval[2*col_idx*NVECS*NSHIFTS + @] + scal_@ * mval_idx;\#2*NSHIFTS*NVECS \
    } \
#GHOST_UNROLL#xval[2*(diag_idx*NVECS*NSHIFTS + @)] += scal_~(2*@)~*(-sigma[2*~@/NVECS~]) - scal_~(2*@+1)~*(sigma[2*~@/NVECS~+1]);xval[2*(diag_idx*NVECS*NSHIFTS + @)+1] += scal_~(2*@)~*sigma[2*~@/NVECS~+1] - scal_~(2*@+1)~*sigma[2*~@/NVECS~];\#NSHIFTS*NVECS \
} \
\

#define BACKWARD_SHIFT_LOOP(start,end,MT,VT) \
for (ghost_lidx row=end-1; row>=start; --row){ \
#GHOST_UNROLL#double rownorm@ = 0;\#NSHIFTS \
#GHOST_UNROLL#double scal_@ = 0;\#2*NSHIFTS*NVECS \
#GHOST_UNROLL#double rp@ = 0;\#NSHIFTS \
#GHOST_UNROLL#double ip@ = 0;\#NSHIFTS \
    \
    double rp_x=0, ip_x=0; \
    double mval_diag = 0; \
    ghost_lidx idx = mat->chunkStart[row]; \
    if(bval != NULL) { \
#GHOST_UNROLL#scal_~(2*@)~ = bval[row*num_blocks+~@%NVECS~];\#NVECS*NSHIFTS \
    } \
    ghost_lidx diag_idx = 0; \
    \
    if(mat->context->row_map->loc_perm != mat->context->col_map->loc_perm) { \
        diag_idx = mat->context->col_map->loc_perm[mat->context->row_map->loc_perm_inv[row]]; \
    } \
    else { \
        diag_idx = row; \
    } \
    ghost_lidx j = 0; \
    for(j=0; j<mat->rowLen[row] && mat->col[idx+j]!=diag_idx; ++j) { \
        MT mval_idx = mval[idx+j]; \
        ghost_lidx col_idx = mat->col[idx+j]; \
#GHOST_UNROLL#scal_@ -= mval_idx*xval[2*col_idx*NVECS*NSHIFTS + @];\#2*NSHIFTS*NVECS \
#GHOST_UNROLL#rownorm@ += mval_idx * mval_idx;\#NSHIFTS \
    } \
    if(j!=mat->rowLen[row]) { \
        mval_diag = mval[idx+j]; \
        diag_idx = diag_idx; \
    } \
    \
#GHOST_UNROLL#rp@ = mval_diag-sigma[2*@];\#NSHIFTS \
#GHOST_UNROLL#ip@ = -sigma[2*@+1];\#NSHIFTS \
#GHOST_UNROLL#rp_x = xval[2*(diag_idx*NVECS*NSHIFTS + @)]; ip_x = xval[2*(diag_idx*NVECS*NSHIFTS + @)+1]; scal_~(2*@)~ += -rp~@/NVECS~*rp_x + ip~@/NVECS~*ip_x; scal_~(2*@+1)~ += -rp~@/NVECS~*ip_x - ip~@/NVECS~*rp_x;\#NSHIFTS*NVECS \
#GHOST_UNROLL#rownorm@ += rp~@~*rp~@~ + ip~@~*ip~@~;\#NSHIFTS \
    \
    for(int k=j+1; k<mat->rowLen[row]; ++k) { \
        MT mval_idx = mval[idx+k]; \
        ghost_lidx col_idx = mat->col[idx+k]; \
#GHOST_UNROLL#scal_@ -= mval_idx*xval[2*col_idx*NVECS*NSHIFTS + @];\#2*NSHIFTS*NVECS \
#GHOST_UNROLL#rownorm@ += mval_idx * mval_idx;\#NSHIFTS \
    } \
    \
#GHOST_UNROLL#scal_@ = (scal_@*omega)/rownorm~(@/(2*NVECS))~;\#2*NSHIFTS*NVECS \
    \
    for (j=0; j<mat->rowLen[row]; j++) { \
        MT mval_idx = mval[idx+j]; \
        ghost_lidx col_idx = mat->col[idx+j]; \
#GHOST_UNROLL#xval[2*col_idx*NVECS*NSHIFTS + @] = xval[2*col_idx*NVECS*NSHIFTS + @] + scal_@ * mval_idx;\#2*NSHIFTS*NVECS \
    } \
#GHOST_UNROLL#xval[2*(diag_idx*NVECS*NSHIFTS + @)] += scal_~(2*@)~*(-sigma[2*~@/NVECS~]) - scal_~(2*@+1)~*(sigma[2*~@/NVECS~+1]);xval[2*(diag_idx*NVECS*NSHIFTS + @)+1] += scal_~(2*@)~*sigma[2*~@/NVECS~+1] - scal_~(2*@+1)~*sigma[2*~@/NVECS~];\#NSHIFTS*NVECS \
} \


#endif

struct KACZ_shift_arg {
    ghost_densemat *b;
    ghost_sparsemat *mat;
    ghost_densemat *x;
    double *omega;
    double *sigma;
};

inline void ghost_kacz_shift_kernel_forward_CHUNKHEIGHT_NVECS_NSHIFTS(int start, int end, void *args)
{
    KACZ_shift_arg* kaczArg = (KACZ_shift_arg *)args;

    ghost_densemat* b = (ghost_densemat *)(kaczArg->b);
    MT *bval = NULL;
    if(b!= NULL)
        bval = (MT *)(b->val);

    MT *xval = (MT *)(kaczArg->x->val);
    MT *mval = (MT *)(kaczArg->mat->val);
    MT omega = *((MT*)(kaczArg->omega));
    ghost_sparsemat *mat = kaczArg->mat;
    double *sigma = (double*) kaczArg->sigma;
    int num_blocks = NVECS;

    FORWARD_SHIFT_LOOP(start,end,MT,VT);
}


inline void ghost_kacz_shift_kernel_backward_CHUNKHEIGHT_NVECS_NSHIFTS(int start, int end, void *args)
{
    KACZ_shift_arg* kaczArg = (KACZ_shift_arg *)args;

    ghost_densemat* b = (ghost_densemat *)(kaczArg->b);
    MT *bval = NULL;
    if(b!= NULL)
        bval = (MT *)(b->val);

    MT *xval = (MT *)(kaczArg->x->val);
    MT *mval = (MT *)(kaczArg->mat->val);
    MT omega = *((MT*)(kaczArg->omega));
    ghost_sparsemat *mat = kaczArg->mat;
    double *sigma = (double*) kaczArg->sigma;
    int num_blocks = NVECS;

    BACKWARD_SHIFT_LOOP(start,end,MT,VT);
}


ghost_error ghost_kacz_RACEshift_u_plain_rm_CHUNKHEIGHT_NVECS_NSHIFTS(ghost_densemat *x, ghost_sparsemat *mat, ghost_densemat *b, ghost_kacz_opts opts)
{
#ifdef GHOST_HAVE_RACE

#if NSHIFTS
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL);

    VT *sigma_z = (VT *)opts.shift;
    double *sigma = (double *)sigma_z;

    int num_shifts = 0, num_blocks = 0;

    if(opts.num_shifts == 0) {
        num_shifts = 1;
    } else {
        num_shifts = opts.num_shifts;
    }

    num_blocks = NVECS; //b->traits.ncols;
    if(num_shifts*num_blocks != x->traits.ncols) {
        GHOST_WARNING_LOG("You have %d shifts requested and %d columns in input vector, but there are only %d columns in the output vector",num_shifts,num_blocks,x->traits.ncols)
    }

    if(!(x->traits.datatype & (ghost_datatype)GHOST_DT_COMPLEX) ) {
        GHOST_WARNING_LOG("If you have specified complex shifts as option, ensure your output vector is also complex type!") 
            //return GHOST_ERR_DATATYPE;
    }

    RACE::Interface *ce = (RACE::Interface*) (mat->context->coloringEngine);

    if(ce== NULL) {
        GHOST_ERROR_LOG("RACE preprocessing not carried out!");
    }

    MT omega_ = *(MT *)opts.omega;
    KACZ_shift_arg *kaczArg = new KACZ_shift_arg;
    kaczArg->mat = mat;
    kaczArg->b = b;
    kaczArg->x = x;
    kaczArg->omega = &omega_;
    kaczArg->sigma = sigma;

    void* argPtr = (void*) (kaczArg);

    int kaczId = -1;
    if (opts.direction == GHOST_KACZ_DIRECTION_FORWARD) {
        kaczId = ce->registerFunction(&ghost_kacz_shift_kernel_forward_CHUNKHEIGHT_NVECS_NSHIFTS, argPtr);
        ce->executeFunction(kaczId);
    }
    else
    {
        kaczId = ce->registerFunction(&ghost_kacz_shift_kernel_backward_CHUNKHEIGHT_NVECS_NSHIFTS, argPtr);
        ce->executeFunction(kaczId, true);
    }

    delete kaczArg;
    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL);
    return GHOST_SUCCESS;
#else
    UNUSED(x);
    UNUSED(mat);
    UNUSED(b);
    UNUSED(opts);
    GHOST_ERROR_LOG("This function should not have been called with 0 shifts!");
    return GHOST_ERR_INVALID_ARG;
#endif
#else
    UNUSED(x);
    UNUSED(mat);
    UNUSED(b);
    UNUSED(opts);
    GHOST_ERROR_LOG("Enable RACE library");
    return GHOST_ERR_INVALID_ARG;
#endif
}

ghost_error ghost_kacz__RACEshift_u_plain_x_x_rm_CHUNKHEIGHT_NVECS_NSHIFTS(ghost_densemat *x, ghost_sparsemat *mat, ghost_densemat *b, ghost_kacz_opts opts)
{
#if NSHIFTS
    ghost_error ret = GHOST_SUCCESS;

    //SELECT_TMPL_1DATATYPE(mat->traits.datatype,std::complex,ret,ghost_kacz_BMCshift_u_plain_cm_CHUNKHEIGHT_NVECS_tmpl,x,mat,b,opts);
    // TODO mixed datatypes
    ret = ghost_kacz_RACEshift_u_plain_rm_CHUNKHEIGHT_NVECS_NSHIFTS(x,mat,b, opts);
    //SELECT_TMPL_2DATATYPES_base_derived(mat->traits.datatype,x->traits.datatype,std::complex,ret,ghost_kacz_BMCshift_u_plain_rm_CHUNKHEIGHT_NVECS_tmpl,x,mat,b,opts);

    return ret;
#else
    UNUSED(x);
    UNUSED(mat);
    UNUSED(b);
    UNUSED(opts);
    GHOST_ERROR_LOG("This function should not have been called with 0 shifts!");
    return GHOST_ERR_INVALID_ARG;
#endif
}


