#include "ghost/config.h"
#include "ghost/types.h"
#include "ghost/util.h"
#include "ghost/densemat.h"
#include "ghost/log.h"
#include "ghost/timing.h"
#include "ghost/locality.h"
#include "ghost/instr.h"
#include "ghost/rand.h"
#include "ghost/tsmm_cu_gen.h"

#include <cuda_runtime.h>
#include <stdio.h>
#include <cublas_v2.h>
#include <curand.h>
#include <sys/types.h>
#include <unistd.h>
#include <complex.h>

#include "ghost/cu_complex.h"
#include "ghost/complex.h"

#define THREADSPERBLOCK 1024

template<typename T,int CFGM, int CFGK> __global__ static void ghost_tsmm_cu_rm_cm(T * const __restrict__ x, const T * const __restrict__ v, const T * const __restrict__ w, const T alpha, const T beta, ghost_lidx_t nrows, ghost_lidx_t stridex, ghost_lidx_t stridev, ghost_lidx_t stridew)
{
    int row = blockIdx.x*blockDim.x+threadIdx.x;
    int k;
    int m;
    T tmp;

    for (;row < nrows; row+=gridDim.x*blockDim.x) {
        for (k=0; k<CFGK; k++) {
            tmp = scale<T>(x[row*stridex+k],beta);
            for (m=0; m<CFGM; m++) {
                tmp = axpy<T,T>(tmp,alpha,scale<T>(v[row*stridev+m],w[k*stridew+m]));
            }
            x[row*stridex+k] = tmp;
        }
    }
}

template<typename T> __global__ static void ghost_tsmm_cu_rm_cm_fallback(T * const __restrict__ x, const T * const __restrict__ v, const T * const __restrict__ w, const T alpha, const T beta, ghost_lidx_t nrows, ghost_lidx_t stridex, ghost_lidx_t stridev, ghost_lidx_t stridew, const int M, const int K)
{
    int row = blockIdx.x*blockDim.x+threadIdx.x;
    int k;
    int m;
    T tmp;

    for (;row < nrows; row+=gridDim.x*blockDim.x) {
        for (k=0; k<K; k++) {
            tmp = scale<T>(x[row*stridex+k],beta);
            for (m=0; m<M; m++) {
                tmp = axpy<T,T>(tmp,alpha,scale<T>(__ldg(&v[row*stridev+m]),__ldg(&w[k*stridew+m])));
            }
            x[row*stridex+k] = tmp;
        }
    }
}

#GHOST_FUNC_BEGIN#CFGK=${CFG_BLOCKVECTOR_SIZES}#CFGM=${CFG_BLOCKVECTOR_SIZES}
ghost_error_t ghost_tsmm__u_cuda_x_CFGK_CFGM_rm_cm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta) 
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL); 
    ghost_error_t ret = GHOST_SUCCESS;
    dim3 block, grid;
    grid.x = (int)ceil((double)x->traits.nrows/THREADSPERBLOCK);
    grid.y = 1;
    grid.z = 1;
    block.x = THREADSPERBLOCK;
    block.y = 1;
    block.z = 1;

    if (x->traits.datatype & GHOST_DT_COMPLEX) {
        if (x->traits.datatype & GHOST_DT_DOUBLE) {
            ghost_tsmm_cu_rm_cm<cuDoubleComplex,CFGM,CFGK><<< grid,block >>>(
                    (cuDoubleComplex *)x->cu_val,(const cuDoubleComplex *)v->cu_val,(const cuDoubleComplex *)w->cu_val,*(cuDoubleComplex *)alpha,*(cuDoubleComplex *)beta,x->traits.nrows,x->stride,v->stride,w->stride);
        } else {
            ghost_tsmm_cu_rm_cm<cuFloatComplex,CFGM,CFGK><<< grid,block >>>(
                    (cuFloatComplex *)x->cu_val,(const cuFloatComplex *)v->cu_val,(const cuFloatComplex *)w->cu_val,*(cuFloatComplex *)alpha,*(cuFloatComplex *)beta,x->traits.nrows,x->stride,v->stride,w->stride);
        }
    } else {
        if (x->traits.datatype & GHOST_DT_DOUBLE) {
            ghost_tsmm_cu_rm_cm<double,CFGM,CFGK><<< grid,block >>>(
                   (double *)x->cu_val,(const double *)v->cu_val,(const double *)w->cu_val,*(double *)alpha,*(double *)beta,x->traits.nrows,x->stride,v->stride,w->stride);
        } else {
            ghost_tsmm_cu_rm_cm<float,CFGM,CFGK><<< grid,block >>>(
                   (float *)x->cu_val,(const float *)v->cu_val,(const float *)w->cu_val,*(float *)alpha,*(float *)beta,x->traits.nrows,x->stride,v->stride,w->stride);
        }
    }

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL); 
    CUDA_CALL_RETURN(cudaGetLastError());
    return ret;
}
#GHOST_FUNC_END

ghost_error_t ghost_tsmm__u_cuda_x_x_x_rm_cm(ghost_densemat_t *x, ghost_densemat_t *v, ghost_densemat_t *w, void *alpha, void *beta) 
{
    GHOST_FUNC_ENTER(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL); 
    ghost_error_t ret = GHOST_SUCCESS;
    dim3 block, grid;
    grid.x = (int)ceil((double)x->traits.nrows/THREADSPERBLOCK);
    grid.y = 1;
    grid.z = 1;
    block.x = THREADSPERBLOCK;
    block.y = 1;
    block.z = 1;

    if (x->traits.datatype & GHOST_DT_COMPLEX) {
        if (x->traits.datatype & GHOST_DT_DOUBLE) {
            ghost_tsmm_cu_rm_cm_fallback<cuDoubleComplex><<< grid,block >>>(
                    (cuDoubleComplex *)x->cu_val,(const cuDoubleComplex *)v->cu_val,(const cuDoubleComplex *)w->cu_val,*(cuDoubleComplex *)alpha,*(cuDoubleComplex *)beta,x->traits.nrows,x->stride,v->stride,w->stride,v->traits.ncols,x->traits.ncols);
        } else {
            ghost_tsmm_cu_rm_cm_fallback<cuFloatComplex><<< grid,block >>>(
                    (cuFloatComplex *)x->cu_val,(const cuFloatComplex *)v->cu_val,(const cuFloatComplex *)w->cu_val,*(cuFloatComplex *)alpha,*(cuFloatComplex *)beta,x->traits.nrows,x->stride,v->stride,w->stride,v->traits.ncols,x->traits.ncols);
        }
    } else {
        if (x->traits.datatype & GHOST_DT_DOUBLE) {
            ghost_tsmm_cu_rm_cm_fallback<double><<< grid,block >>>(
                   (double *)x->cu_val,(const double *)v->cu_val,(const double *)w->cu_val,*(double *)alpha,*(double *)beta,x->traits.nrows,x->stride,v->stride,w->stride,v->traits.ncols,x->traits.ncols);
        } else {
            ghost_tsmm_cu_rm_cm_fallback<float><<< grid,block >>>(
                   (float *)x->cu_val,(const float *)v->cu_val,(const float *)w->cu_val,*(float *)alpha,*(float *)beta,x->traits.nrows,x->stride,v->stride,w->stride,v->traits.ncols,x->traits.ncols);
        }
    }

    GHOST_FUNC_EXIT(GHOST_FUNCTYPE_MATH|GHOST_FUNCTYPE_KERNEL); 
    CUDA_CALL_RETURN(cudaGetLastError());
    return ret;
}
